# Understanding and wrangling data

## Introduction to the dataset.

We will be introducing `birthwt` dataset from the `MASS` package which was collected at Baystate Medical Center, Springfield, Mass during 1986 on *Risk Factors Associated with Low Infant Birth Weight*.

::: column-margin
::: callout-important
The same dataset can be loaded directly from the `MASS` package. However, for additional learnings, we have provided the dataset in varied formats for the participants to learn data import during the group activities.
:::
:::

## Create project

We would like to reiterate that creating a project and required folders at the beginning of a research work is a gold standard database management strategy. Go ahead and create your own projects and folders for the activity.

## Load libraries

To use functions from varied packages/ libraries other than baseR, we need to explicitly load those libraries. For this session, following libraries will be used:-

::: column-margin
::: {.callout-note}
The loading of libraries into your current session can be optional. In case you are going to use a function only once from a library, it is computationally better to explicity call the function using `::`. Discuss! 
:::
:::

1.  `rio`: A Swiss-Army Knife for Data I/O ([Click to learn more](https://gesistsa.github.io/rio/))
2.  `tidyverse`: R packages for Data Science ([Click to learn more](https://www.tidyverse.org/))
3.  `skimr`: For quick summary statistics ([Click to learn more](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html))
4.  `here`: A Simpler Way to Find Your Files ([Click to learn more](https://here.r-lib.org/))
5.  `MASS`: Functions and datasets to support Venables and Ripley, "Modern Applied Statistics with S" (4th edition, 2002) ([Click to learn more](https://cran.r-project.org/web/packages/MASS/index.html))

```{r}
library(tidyverse)
library(gtsummary)
```


## Load data

```{r}
df <- MASS::birthwt
```

## Know the class of your data

`R` possesses a simple generic function mechanism which can be used for an object-oriented style of programming (OOP). Method dispatch takes place based on the class of the first argument to the generic function.

::: column-margin
::: {.callout-important}
When dealing with rectagular spreadsheets, it is a good habit to set the class of the dataset to tibble for a tidy analysis.
:::
:::

```{r}
class(df)
```
## Setting dataset class to tibble

```{r}
df <- df |> as_tibble()
class(df)
```

## Loading data from a folder

`import` function from the `rio` package read a `data.frame` from a file. Exceptions to this rule are `Rdata`, `RDS`, and `JSON` input file formats, which return the originally saved object without changing its class. To set a class, we can use an argument `setclass`.


```{r}
df <- rio::import(here::here("data",
                             "lbw.dta"),
                  setclass = "tibble")
class(df)
```

## Understand structure of the data.

### Using the `glimpse` function.


`glimpse()` is like a transposed version of `print()`: columns run down the page, and data runs across. This makes it possible to see every column in a data frame. It's a little like `str()` applied to a data frame but it tries to show you as much data as possible. 


```{r}
glimpse(df)
```
::: column-margin
::: {.callout-important}
Understanding the data structure helps you understand the way data cleaning/wrangling and subsequent analysis is required. Here, the `birthwt` data frame has 189 rows and 10 columns. All the variables are `dbl` (means double precision, a quantitative variable that is essentially continuous - taking decimal values). 
:::
:::

### Using the `summary` function

::: column-margin
`summary()` is a generic function used to produce result summaries of the results of various model fitting functions. The function invokes particular methods which depend on the class of the first argument.
:::

```{r}
summary(df)
```


### Using the `skim` function.

::: column-margin
`skim()` is an alternative to `summary()`, quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.
:::

```{r}
skimr::skim(df)
```




## Data wrangling.

`dplyr` is a package grouped inside `tidyverse` collection of packages. `dplyr` package is very useful to "munge", "wrangle", or "transform" your data. It is a **grammar of data manipulation**. It provides a consistent set of verbs that help you solve the most common data manipulation challenges.  

::: column-margin
::: {.callout-tip}
**The common data wrangling functions include**:

6. `rename()`: To change the names of the variables.  
1. `select()`: To reduce the size of dataset by selecting certain variables (or columns).  
2. `mutate()`: To generate new variable/ transform existing variables.  
3. `arrange()`: To sort observation of a variable.  
4. `filter()`: To group observations based on certain criteria.  
5. `group_by()`: To reduce variables to groups in order to estimate summary statistic. 

:::
:::


### Renaming variable names

`rename()` provides several advantages over traditional renaming methods, especially in the context of data manipulation.   

- The syntax for `rename()` is concise and intuitive. You specify the new column name first, making it easier to read and understand.   
- `rename()` integrates well with the pipe operator (` |> `), which allows chaining multiple data manipulation steps.   
- `rename()` allows you to rename only the columns you need without affecting others. This is convenient when working with large datasets.   
- If you try to rename a column that doesnâ€™t exist, `rename()` throws an informative error, helping catch *typos* early. **This behavior is safer compared to manually changing column names, where typos might go unnoticed**.

```{r}
df <- df |> 
  rename(child_weight_cat = low,
         maternal_age = age,
         maternal_weight = lwt,
         number_preterm = ptl,
         hypertension = ht,
         uterine_irritability = ui,
         health_visits = ftv,
         birth_weight = bwt)
names(df)
```



### Select only maternal weight, smoking, and birth weight

```{r}
df |> 
  select(maternal_weight,
         smoke,
         birth_weight)
```



### Mutate smoking history, race, and child_weight_cat as categorical/factor variable

The function `factor` is used to encode a vector as a factor. The same can be used within the mutate function as an argument for data transformation. 

::: column-margin

Try using if else!

```{r}
#| eval: false
#| code-fold: false

df |> 
  mutate(
    smoke_cat = if_else(
      smoke == 1, "Smoker", "Non-Smoker"))

```
:::



```{r}
df <- df |> 
  mutate(smoke_cat = factor(smoke, 
                            levels = c(0,1),
                            labels = c("Non-smoker",
                                       "Smoker")),
         race_cat = factor(race,
                           levels = c(1,2,3),
                           labels = c("White",
                                      "Black",
                                      "Other")),
         child_weight_cat = factor(child_weight_cat,
                                   levels = c(0,1),
                                   labels = c("Normal", "Low Birth Weight")))
df |> 
  select(smoke_cat, race_cat, child_weight_cat) |> 
  summary()
```



### Arrange maternal age to show lowest age group

```{r}
df |> 
  arrange(maternal_age) |> 
  head()
```

### Arrange maternal age to show lowest age group

```{r}
df |> 
  arrange(-maternal_age) |> 
  head()
```

### Filter dataset for only mothers with Black race

```{r}
df |> 
  filter(race_cat == "Black")
```



### Group dataset by category of maternal race.

Most data operations are done on groups defined by variables. `group_by()` takes an existing tbl and converts it into a grouped tbl where operations are performed "by group". 

```{r}
df |> 
  group_by(race_cat)
```



## Summary.

In this session, we worked on understanding the data structure, variable names, class, and used `dplyr` verbs for data wrangling. Once the dataset is ready for analysis, we move towards Exploratory Data Analysis. It is an iterative process for a robust analysis later.



















