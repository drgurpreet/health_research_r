[
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "1 Exploratory Data Analysis (Summary Figures)",
    "section": "",
    "text": "The present session will focus on basics of data visualization. The process of visualization and creation of summary tables go hand in hand, however, we shall limit our discussion to creating beautiful figures here!\nBefore we start with learning how to create graphs/ plots/ figures using R, it is important to understand that the selection of type of plots is dependent entirely upon the number and type of variables selected. It is strongly recommended that the same be refreshed and strengthened by participants from time to time for advanced use of data analytics in future.\n\n\n\n\n\n\n\n\nProgramming Basics\n\n\n\nData visualization is a powerful tool for data science in epidemiology. The basics of programming for creating plots using ggplot package includes understanding of four important aspects.\n\nUse of reusable/ reproducible templates.\n\nCreation of different types of plots using geoms.\n\nAddition of variables using mapping.\n\nCustomization of plots using settings.\n\n\n\n\n\n\n\n\n\nFor illustration, we will plot birth weights to understand the distribution pattern among all study participants in birth weight data set.\n\nCode\nggplot(data = df) + # Template\n  geom_histogram( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    color = \"blue\", # optional settings\n    fill = \"red\",\n    linetype = 2,\n    alpha = 0.8,\n    size = 1) \nggplot(data = df) + # Template\n  geom_freqpoly( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    color = \"blue\", # optional settings\n    fill = \"red\",\n    linetype = 2,\n    alpha = 0.8,\n    size = 1) \n\n\n\n\nHistogram\n\n\n\n\n\n\n\n\n\n\n\nFrequency polygon\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df) + # Template\n  geom_dotplot( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    size = 1) \nggplot(data = df) + # Template\n  geom_boxplot( # geom\n    mapping = aes(y = birth_weight), # mapping\n    size = 1) \n\n\n\n\nDot plot\n\n\n\n\n\n\n\n\n\n\n\nBox plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the birth weight dataset, if we are interested to understand the distribution of smoking history (Present/Absent) among mothers.\n\n\nAdd optional arguments (settings) to enhance visualizations.\nWhat happens if instead of writing {mapping = aes()}, we write only {aes()} in the code chunk?\n\nCode\nggplot(data = df) +\n  geom_bar(mapping = aes(x = smoke_cat)) \nggplot(data = df) +\n  geom_bar(mapping = aes(y = smoke_cat)) \n\n\n\n\nBar chart (Vertical)\n\n\n\n\n\n\n\n\n\n\n\nBar chart (Horizontal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the birth weights dataset, mother’s weight at last menstrual period and birth weight of the infant are continuous variables. We might be interested in looking at how mother’s weight is associated with birth weight of an infant.\n\nCode\nggplot(data = df) + \n  geom_point(aes(x = maternal_weight, y = birth_weight), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) \nggplot(data = df) + \n  geom_point(aes(x = maternal_weight, y = birth_weight), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) +\n  geom_smooth(aes(x = maternal_weight, y = birth_weight),\n              method = \"lm\")\n\n\n\n\nScatter Plot\n\n\n\n\n\n\n\n\n\n\n\nScatter Plot with Regression line\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the birth weights dataset, smoking history is categorical and birth weight is a continuous variable. We might be interested to estimate if maternal smoking history has effect on infant birth weights.\n\nCode\nggplot(data = df) + \n  geom_bar(aes(x = smoke_cat, y = birth_weight),\n           stat = \"identity\") +\n  labs(x = \"Smoking History\",\n       y = \"Birth Weight\")\nggplot(data = df) + \n  geom_boxplot(aes(x = smoke_cat, y = birth_weight),\n               coef = 1.5)\n\n\n\n\nMultiple bar chart\n\n\n\n\n\n\n\n\n\n\n\nBox and Whisker plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the dataset, smoking history and whether the infants birth weight was low or not are two discrete/ categorical variables. As a researcher, we would like to see the relationship between these two discrete variables.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo see relationships between two discrete variables, multiple bar charts and component bar charts are used. Till now, the fill argument has been used in the setting section of the code. If you look carefully, while in the setting section, we manually placed the value/ color. The same argument can also be used in mapping section within aesthetics.\n\n\n\n\nCode\nggplot(data = df) + \n  geom_bar(aes(x = smoke_cat, fill = race_cat),\n           position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, you know how to create the basic plot. However, plot has additional components such as title, subtitle, caption, axis labels, legend, etc. The same also requires deliberation and details for the same can be learnt from multiple resources. We recommend R Graphics Cookbook https://r-graphics.org/ as a good resource for the same. We are introducing you to this important aspect of data visualization, however considering the present workshop as an introductory workshop, we shall introduce you to AI powered programming for beginners, however, we plan to cover additional aspects such as animated plots, 3D plots, spatial plots, other ggplot extensions, etc during intermediate/ advanced levels only. Enjoy plotting!!"
  },
  {
    "objectID": "visualization.html#introduction.",
    "href": "visualization.html#introduction.",
    "title": "1 Exploratory Data Analysis (Summary Figures)",
    "section": "",
    "text": "The present session will focus on basics of data visualization. The process of visualization and creation of summary tables go hand in hand, however, we shall limit our discussion to creating beautiful figures here!\nBefore we start with learning how to create graphs/ plots/ figures using R, it is important to understand that the selection of type of plots is dependent entirely upon the number and type of variables selected. It is strongly recommended that the same be refreshed and strengthened by participants from time to time for advanced use of data analytics in future.\n\n\n\n\n\n\n\n\nProgramming Basics\n\n\n\nData visualization is a powerful tool for data science in epidemiology. The basics of programming for creating plots using ggplot package includes understanding of four important aspects.\n\nUse of reusable/ reproducible templates.\n\nCreation of different types of plots using geoms.\n\nAddition of variables using mapping.\n\nCustomization of plots using settings."
  },
  {
    "objectID": "visualization.html#visualization-of-single-variable.",
    "href": "visualization.html#visualization-of-single-variable.",
    "title": "1 Exploratory Data Analysis (Summary Figures)",
    "section": "",
    "text": "For illustration, we will plot birth weights to understand the distribution pattern among all study participants in birth weight data set.\n\nCode\nggplot(data = df) + # Template\n  geom_histogram( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    color = \"blue\", # optional settings\n    fill = \"red\",\n    linetype = 2,\n    alpha = 0.8,\n    size = 1) \nggplot(data = df) + # Template\n  geom_freqpoly( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    color = \"blue\", # optional settings\n    fill = \"red\",\n    linetype = 2,\n    alpha = 0.8,\n    size = 1) \n\n\n\n\nHistogram\n\n\n\n\n\n\n\n\n\n\n\nFrequency polygon\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = df) + # Template\n  geom_dotplot( # geom\n    mapping = aes(x = birth_weight), # mapping\n    binwidth = 350, # mandatory settings\n    size = 1) \nggplot(data = df) + # Template\n  geom_boxplot( # geom\n    mapping = aes(y = birth_weight), # mapping\n    size = 1) \n\n\n\n\nDot plot\n\n\n\n\n\n\n\n\n\n\n\nBox plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the birth weight dataset, if we are interested to understand the distribution of smoking history (Present/Absent) among mothers.\n\n\nAdd optional arguments (settings) to enhance visualizations.\nWhat happens if instead of writing {mapping = aes()}, we write only {aes()} in the code chunk?\n\nCode\nggplot(data = df) +\n  geom_bar(mapping = aes(x = smoke_cat)) \nggplot(data = df) +\n  geom_bar(mapping = aes(y = smoke_cat)) \n\n\n\n\nBar chart (Vertical)\n\n\n\n\n\n\n\n\n\n\n\nBar chart (Horizontal)"
  },
  {
    "objectID": "visualization.html#visualization-of-two-variables.",
    "href": "visualization.html#visualization-of-two-variables.",
    "title": "1 Exploratory Data Analysis (Summary Figures)",
    "section": "",
    "text": "Illustrative example: In the birth weights dataset, mother’s weight at last menstrual period and birth weight of the infant are continuous variables. We might be interested in looking at how mother’s weight is associated with birth weight of an infant.\n\nCode\nggplot(data = df) + \n  geom_point(aes(x = maternal_weight, y = birth_weight), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) \nggplot(data = df) + \n  geom_point(aes(x = maternal_weight, y = birth_weight), \n             color = \"red\",\n             size = 1,\n             shape = 1,\n             stroke = 1) +\n  geom_smooth(aes(x = maternal_weight, y = birth_weight),\n              method = \"lm\")\n\n\n\n\nScatter Plot\n\n\n\n\n\n\n\n\n\n\n\nScatter Plot with Regression line\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the birth weights dataset, smoking history is categorical and birth weight is a continuous variable. We might be interested to estimate if maternal smoking history has effect on infant birth weights.\n\nCode\nggplot(data = df) + \n  geom_bar(aes(x = smoke_cat, y = birth_weight),\n           stat = \"identity\") +\n  labs(x = \"Smoking History\",\n       y = \"Birth Weight\")\nggplot(data = df) + \n  geom_boxplot(aes(x = smoke_cat, y = birth_weight),\n               coef = 1.5)\n\n\n\n\nMultiple bar chart\n\n\n\n\n\n\n\n\n\n\n\nBox and Whisker plots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllustrative example: In the dataset, smoking history and whether the infants birth weight was low or not are two discrete/ categorical variables. As a researcher, we would like to see the relationship between these two discrete variables.\n\n\n\n\n\n\n\n\nNote\n\n\n\nTo see relationships between two discrete variables, multiple bar charts and component bar charts are used. Till now, the fill argument has been used in the setting section of the code. If you look carefully, while in the setting section, we manually placed the value/ color. The same argument can also be used in mapping section within aesthetics.\n\n\n\n\nCode\nggplot(data = df) + \n  geom_bar(aes(x = smoke_cat, fill = race_cat),\n           position = \"dodge\")"
  },
  {
    "objectID": "visualization.html#way-forward",
    "href": "visualization.html#way-forward",
    "title": "1 Exploratory Data Analysis (Summary Figures)",
    "section": "",
    "text": "Now, you know how to create the basic plot. However, plot has additional components such as title, subtitle, caption, axis labels, legend, etc. The same also requires deliberation and details for the same can be learnt from multiple resources. We recommend R Graphics Cookbook https://r-graphics.org/ as a good resource for the same. We are introducing you to this important aspect of data visualization, however considering the present workshop as an introductory workshop, we shall introduce you to AI powered programming for beginners, however, we plan to cover additional aspects such as animated plots, 3D plots, spatial plots, other ggplot extensions, etc during intermediate/ advanced levels only. Enjoy plotting!!"
  },
  {
    "objectID": "stat_summaries.html",
    "href": "stat_summaries.html",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "Till now, you have been exploring and understanding datasets. After EDA, the analysis phase is undertaken wherein you need to look carefully at associations between the outcome and exposure variables, in other words, independent and dependent variables. There can be two variables wherein you are interested in associations such as independent sample t-tests for difference between means, or a Chi-square test, or paired test, etc depending on the variables and Research Questions.\nIn this session, we shall take you through some commonly used tests and their presentation tables including basics of regression models.\n\n\n\n\n\nFor this question, the summary statistics should be split by birth weight categories, which can be done by using the by= argument. To compare two or more groups, include add_p() with the function call, which detects variable type and uses an appropriate statistical test.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe tbl_summary() provides outputs and inferential statistics according to computed distribution. It is important to consider which test to apply and when.. discuss!!\n\n\n\n\nCode\ndf |&gt; \n  select(-smoke,\n         -race) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = child_weight_cat\n  ) |&gt; \n  add_p()\n\n\n\n\n\n\n\n\nCharacteristic\nNormal, N = 1301\nLow Birth Weight, N = 591\np-value2\n\n\n\n\nMaternal Age\n23.7, 5.6\n22.3, 4.5\n0.2\n\n\nMaternal Weight\n133, 32\n122, 27\n0.013\n\n\nnumber_preterm\n\n\n&lt;0.001\n\n\n    0\n118 (91%)\n41 (69%)\n\n\n\n    1\n8 (6.2%)\n16 (27%)\n\n\n\n    2\n3 (2.3%)\n2 (3.4%)\n\n\n\n    3\n1 (0.8%)\n0 (0%)\n\n\n\nhypertension\n5 (3.8%)\n7 (12%)\n0.052\n\n\nuterine_irritability\n14 (11%)\n14 (24%)\n0.020\n\n\nhealth_visits\n\n\n0.3\n\n\n    0\n64 (49%)\n36 (61%)\n\n\n\n    1\n36 (28%)\n11 (19%)\n\n\n\n    2\n23 (18%)\n7 (12%)\n\n\n\n    3\n3 (2.3%)\n4 (6.8%)\n\n\n\n    4\n3 (2.3%)\n1 (1.7%)\n\n\n\n    6\n1 (0.8%)\n0 (0%)\n\n\n\nbirth_weight\n3,329, 478\n2,097, 391\n&lt;0.001\n\n\nSmoking History\n\n\n0.026\n\n\n    Non-smoker\n86 (66%)\n29 (49%)\n\n\n\n    Smoker\n44 (34%)\n30 (51%)\n\n\n\nrace_cat\n\n\n0.082\n\n\n    White\n73 (56%)\n23 (39%)\n\n\n\n    Black\n15 (12%)\n11 (19%)\n\n\n\n    Other\n42 (32%)\n25 (42%)\n\n\n\n\n1 Mean, SD; n (%)\n\n\n2 Wilcoxon rank sum test; Fisher’s exact test; Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(-smoke,\n         -race) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = child_weight_cat\n  ) |&gt; \n  add_p(all_continuous() ~ \"t.test\")\n\n\n\n\n\n\n\n\nCharacteristic\nNormal, N = 1301\nLow Birth Weight, N = 591\np-value2\n\n\n\n\nMaternal Age\n23.7, 5.6\n22.3, 4.5\n0.078\n\n\nMaternal Weight\n133, 32\n122, 27\n0.013\n\n\nnumber_preterm\n\n\n&lt;0.001\n\n\n    0\n118 (91%)\n41 (69%)\n\n\n\n    1\n8 (6.2%)\n16 (27%)\n\n\n\n    2\n3 (2.3%)\n2 (3.4%)\n\n\n\n    3\n1 (0.8%)\n0 (0%)\n\n\n\nhypertension\n5 (3.8%)\n7 (12%)\n0.052\n\n\nuterine_irritability\n14 (11%)\n14 (24%)\n0.020\n\n\nhealth_visits\n\n\n0.3\n\n\n    0\n64 (49%)\n36 (61%)\n\n\n\n    1\n36 (28%)\n11 (19%)\n\n\n\n    2\n23 (18%)\n7 (12%)\n\n\n\n    3\n3 (2.3%)\n4 (6.8%)\n\n\n\n    4\n3 (2.3%)\n1 (1.7%)\n\n\n\n    6\n1 (0.8%)\n0 (0%)\n\n\n\nbirth_weight\n3,329, 478\n2,097, 391\n&lt;0.001\n\n\nSmoking History\n\n\n0.026\n\n\n    Non-smoker\n86 (66%)\n29 (49%)\n\n\n\n    Smoker\n44 (34%)\n30 (51%)\n\n\n\nrace_cat\n\n\n0.082\n\n\n    White\n73 (56%)\n23 (39%)\n\n\n\n    Black\n15 (12%)\n11 (19%)\n\n\n\n    Other\n42 (32%)\n25 (42%)\n\n\n\n\n1 Mean, SD; n (%)\n\n\n2 Welch Two Sample t-test; Fisher’s exact test; Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n\nExample. As a researcher, you might be interested in knowing the correlation between maternal weight, number of preterm births, number of health visits and child birth weight.\n\n\nCode\nGGally::ggpairs(df |&gt; \n          select(maternal_age, maternal_weight,\n                 number_preterm, health_visits,\n                 birth_weight),\n        title=\"Illustration: Correlation Matrix\") \n\n\n\n\n\n\n\n\n\n\n\n\nThe tbl_regression() function takes a regression model object in R and returns a formatted table of regression model results that is publication-ready. It is a simple way to summarize and present your analysis results using R! Like tbl_summary(), tbl_regression() creates highly customizable analytic tables with sensible defaults.\n\n\nCode\n# build logistic regression model\nm1 &lt;- glm(child_weight_cat ~ maternal_age + smoke_cat, \n          data = df, \n          family = binomial)\n\n# view raw model results\nsummary(m1)$coefficients\n\n\n                   Estimate Std. Error     z value   Pr(&gt;|z|)\n(Intercept)      0.06090554 0.75731970  0.08042249 0.93590124\nmaternal_age    -0.04977927 0.03197195 -1.55696724 0.11947826\nsmoke_catSmoker  0.69184868 0.32180606  2.14989327 0.03156366\n\n\nCode\n# Create presentation table\ntbl_regression(m1, exponentiate = TRUE)\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\nmaternal_age\n0.95\n0.89, 1.01\n0.12\n\n\nsmoke_cat\n\n\n\n\n\n    Non-smoker\n—\n—\n\n\n\n    Smoker\n2.00\n1.06, 3.77\n0.032\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we have introduced you to creating presentable tables for inferential statistics, correlation, and regression tables. Considering time, we are not dwelling deep into which test to apply and when concept. Rather we have focused on how to do them. It is strongly recommended to use these powerful tools in consultation with a Statistician/ Epidemiologist for meaningful inferences and robust methodologies. Hope you had an enjoyable learning during the sessions and we could answer your queries and show you additional resources during the workshop. Be in touch…Happy Learning!"
  },
  {
    "objectID": "stat_summaries.html#introduction.",
    "href": "stat_summaries.html#introduction.",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "Till now, you have been exploring and understanding datasets. After EDA, the analysis phase is undertaken wherein you need to look carefully at associations between the outcome and exposure variables, in other words, independent and dependent variables. There can be two variables wherein you are interested in associations such as independent sample t-tests for difference between means, or a Chi-square test, or paired test, etc depending on the variables and Research Questions.\nIn this session, we shall take you through some commonly used tests and their presentation tables including basics of regression models."
  },
  {
    "objectID": "stat_summaries.html#inferential-statistics-an-overview",
    "href": "stat_summaries.html#inferential-statistics-an-overview",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "For this question, the summary statistics should be split by birth weight categories, which can be done by using the by= argument. To compare two or more groups, include add_p() with the function call, which detects variable type and uses an appropriate statistical test.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThe tbl_summary() provides outputs and inferential statistics according to computed distribution. It is important to consider which test to apply and when.. discuss!!\n\n\n\n\nCode\ndf |&gt; \n  select(-smoke,\n         -race) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = child_weight_cat\n  ) |&gt; \n  add_p()\n\n\n\n\n\n\n\n\nCharacteristic\nNormal, N = 1301\nLow Birth Weight, N = 591\np-value2\n\n\n\n\nMaternal Age\n23.7, 5.6\n22.3, 4.5\n0.2\n\n\nMaternal Weight\n133, 32\n122, 27\n0.013\n\n\nnumber_preterm\n\n\n&lt;0.001\n\n\n    0\n118 (91%)\n41 (69%)\n\n\n\n    1\n8 (6.2%)\n16 (27%)\n\n\n\n    2\n3 (2.3%)\n2 (3.4%)\n\n\n\n    3\n1 (0.8%)\n0 (0%)\n\n\n\nhypertension\n5 (3.8%)\n7 (12%)\n0.052\n\n\nuterine_irritability\n14 (11%)\n14 (24%)\n0.020\n\n\nhealth_visits\n\n\n0.3\n\n\n    0\n64 (49%)\n36 (61%)\n\n\n\n    1\n36 (28%)\n11 (19%)\n\n\n\n    2\n23 (18%)\n7 (12%)\n\n\n\n    3\n3 (2.3%)\n4 (6.8%)\n\n\n\n    4\n3 (2.3%)\n1 (1.7%)\n\n\n\n    6\n1 (0.8%)\n0 (0%)\n\n\n\nbirth_weight\n3,329, 478\n2,097, 391\n&lt;0.001\n\n\nSmoking History\n\n\n0.026\n\n\n    Non-smoker\n86 (66%)\n29 (49%)\n\n\n\n    Smoker\n44 (34%)\n30 (51%)\n\n\n\nrace_cat\n\n\n0.082\n\n\n    White\n73 (56%)\n23 (39%)\n\n\n\n    Black\n15 (12%)\n11 (19%)\n\n\n\n    Other\n42 (32%)\n25 (42%)\n\n\n\n\n1 Mean, SD; n (%)\n\n\n2 Wilcoxon rank sum test; Fisher’s exact test; Pearson’s Chi-squared test\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(-smoke,\n         -race) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = child_weight_cat\n  ) |&gt; \n  add_p(all_continuous() ~ \"t.test\")\n\n\n\n\n\n\n\n\nCharacteristic\nNormal, N = 1301\nLow Birth Weight, N = 591\np-value2\n\n\n\n\nMaternal Age\n23.7, 5.6\n22.3, 4.5\n0.078\n\n\nMaternal Weight\n133, 32\n122, 27\n0.013\n\n\nnumber_preterm\n\n\n&lt;0.001\n\n\n    0\n118 (91%)\n41 (69%)\n\n\n\n    1\n8 (6.2%)\n16 (27%)\n\n\n\n    2\n3 (2.3%)\n2 (3.4%)\n\n\n\n    3\n1 (0.8%)\n0 (0%)\n\n\n\nhypertension\n5 (3.8%)\n7 (12%)\n0.052\n\n\nuterine_irritability\n14 (11%)\n14 (24%)\n0.020\n\n\nhealth_visits\n\n\n0.3\n\n\n    0\n64 (49%)\n36 (61%)\n\n\n\n    1\n36 (28%)\n11 (19%)\n\n\n\n    2\n23 (18%)\n7 (12%)\n\n\n\n    3\n3 (2.3%)\n4 (6.8%)\n\n\n\n    4\n3 (2.3%)\n1 (1.7%)\n\n\n\n    6\n1 (0.8%)\n0 (0%)\n\n\n\nbirth_weight\n3,329, 478\n2,097, 391\n&lt;0.001\n\n\nSmoking History\n\n\n0.026\n\n\n    Non-smoker\n86 (66%)\n29 (49%)\n\n\n\n    Smoker\n44 (34%)\n30 (51%)\n\n\n\nrace_cat\n\n\n0.082\n\n\n    White\n73 (56%)\n23 (39%)\n\n\n\n    Black\n15 (12%)\n11 (19%)\n\n\n\n    Other\n42 (32%)\n25 (42%)\n\n\n\n\n1 Mean, SD; n (%)\n\n\n2 Welch Two Sample t-test; Fisher’s exact test; Pearson’s Chi-squared test"
  },
  {
    "objectID": "stat_summaries.html#correlation-matrices",
    "href": "stat_summaries.html#correlation-matrices",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "Example. As a researcher, you might be interested in knowing the correlation between maternal weight, number of preterm births, number of health visits and child birth weight.\n\n\nCode\nGGally::ggpairs(df |&gt; \n          select(maternal_age, maternal_weight,\n                 number_preterm, health_visits,\n                 birth_weight),\n        title=\"Illustration: Correlation Matrix\")"
  },
  {
    "objectID": "stat_summaries.html#regression-analysis-tables",
    "href": "stat_summaries.html#regression-analysis-tables",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "The tbl_regression() function takes a regression model object in R and returns a formatted table of regression model results that is publication-ready. It is a simple way to summarize and present your analysis results using R! Like tbl_summary(), tbl_regression() creates highly customizable analytic tables with sensible defaults.\n\n\nCode\n# build logistic regression model\nm1 &lt;- glm(child_weight_cat ~ maternal_age + smoke_cat, \n          data = df, \n          family = binomial)\n\n# view raw model results\nsummary(m1)$coefficients\n\n\n                   Estimate Std. Error     z value   Pr(&gt;|z|)\n(Intercept)      0.06090554 0.75731970  0.08042249 0.93590124\nmaternal_age    -0.04977927 0.03197195 -1.55696724 0.11947826\nsmoke_catSmoker  0.69184868 0.32180606  2.14989327 0.03156366\n\n\nCode\n# Create presentation table\ntbl_regression(m1, exponentiate = TRUE)\n\n\n\n\n\n\n\n\nCharacteristic\nOR1\n95% CI1\np-value\n\n\n\n\nmaternal_age\n0.95\n0.89, 1.01\n0.12\n\n\nsmoke_cat\n\n\n\n\n\n    Non-smoker\n—\n—\n\n\n\n    Smoker\n2.00\n1.06, 3.77\n0.032\n\n\n\n1 OR = Odds Ratio, CI = Confidence Interval"
  },
  {
    "objectID": "stat_summaries.html#summary.",
    "href": "stat_summaries.html#summary.",
    "title": "1 Statistical Summary Tables",
    "section": "",
    "text": "In this section, we have introduced you to creating presentable tables for inferential statistics, correlation, and regression tables. Considering time, we are not dwelling deep into which test to apply and when concept. Rather we have focused on how to do them. It is strongly recommended to use these powerful tools in consultation with a Statistician/ Epidemiologist for meaningful inferences and robust methodologies. Hope you had an enjoyable learning during the sessions and we could answer your queries and show you additional resources during the workshop. Be in touch…Happy Learning!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Preface",
    "section": "",
    "text": "Welcome to the “Research Methodology” workshop being conducted by National Health System Resource Centre, New Delhi on 25-26 Oct 2024! Get ready to embark on a transformative journey into the dynamic world of Research and health data science approach using R. This companion workbook is your roadmap and toolkit for our action-packed adventure in R. There are additional resources provided to you during the workshop, however, we shall limit this companion on how you can build solid foundations in research using R and RStudio. We’re here to build a rock-solid foundation in data science specifically for healthcare professionals, all while harnessing the full power of the R programming language and the RStudio interface.\n\n\nOur mission is simple yet ambitious: to empower you with the essential tools and knowledge to undertake epidemiology and health data science projects using R. You’ll dive deep into the R programming language, navigate the versatile RStudio environment, and leverage the tidyverse workflow for cutting-edge data analysis. By the end, you’ll be a healthcare professional who is equipped with the concepts and information needed to make your path in the exciting world of Healthcare research and Health Data Science.\n\n\n\n\n\nLearn to clean, reshape, and prepare your datasets like a pro, tackling common challenges using the power of data manipulation and transformation.\n\n\n\nLearn to create informative and aesthetically pleasing charts using the versatile ggplot2 package. Turn data into compelling stories with stunning visualizations using various ggplot extensions.\n\n\n\nLearn to create Publication ready summary tables for descriptive and inferential statistics.\n\n\n\nLearn to document your processes meticulously, ensuring your analyses are transparent, replicable, and credible. Kick-start you research journey with reproducible workflows.\n\n\n\n\nBy the end of this workshop, you’ll be able to undertake:\n\nData Wrangling: Import data from various sources into R, clean and pre-process data for further analysis and transform data to explore insights and interpretations.\nData Visualization: Create a variety of data visualizations (plots and charts), customize visualizations to highlight key trends and communicate them effectively and apply the best practices of data visualization to make them impactful.\nReproducible Research: Clear and well-documented research workflows, efficiently organise your data and files for epidemiological research and data-science projects.\n\nThis workshop isn’t just about learning - it’s about transforming the way you interact with data. Whether you’re a beginner eager to dive into the world of programming or a seasoned professional looking to sharpen your skills, this workshop is designed to provide practical knowledge and hands-on experience that will set you apart.\nWe’re thrilled to have you join us and can’t wait to see the incredible things you’ll achieve with your new found skills in health data science using R. Let’s dive in and start this exciting journey together!"
  },
  {
    "objectID": "index.html#workshop-goals.",
    "href": "index.html#workshop-goals.",
    "title": "Preface",
    "section": "",
    "text": "Our mission is simple yet ambitious: to empower you with the essential tools and knowledge to undertake epidemiology and health data science projects using R. You’ll dive deep into the R programming language, navigate the versatile RStudio environment, and leverage the tidyverse workflow for cutting-edge data analysis. By the end, you’ll be a healthcare professional who is equipped with the concepts and information needed to make your path in the exciting world of Healthcare research and Health Data Science."
  },
  {
    "objectID": "index.html#key-topics.",
    "href": "index.html#key-topics.",
    "title": "Preface",
    "section": "",
    "text": "Learn to clean, reshape, and prepare your datasets like a pro, tackling common challenges using the power of data manipulation and transformation.\n\n\n\nLearn to create informative and aesthetically pleasing charts using the versatile ggplot2 package. Turn data into compelling stories with stunning visualizations using various ggplot extensions.\n\n\n\nLearn to create Publication ready summary tables for descriptive and inferential statistics.\n\n\n\nLearn to document your processes meticulously, ensuring your analyses are transparent, replicable, and credible. Kick-start you research journey with reproducible workflows."
  },
  {
    "objectID": "index.html#expected-outcomes.",
    "href": "index.html#expected-outcomes.",
    "title": "Preface",
    "section": "",
    "text": "By the end of this workshop, you’ll be able to undertake:\n\nData Wrangling: Import data from various sources into R, clean and pre-process data for further analysis and transform data to explore insights and interpretations.\nData Visualization: Create a variety of data visualizations (plots and charts), customize visualizations to highlight key trends and communicate them effectively and apply the best practices of data visualization to make them impactful.\nReproducible Research: Clear and well-documented research workflows, efficiently organise your data and files for epidemiological research and data-science projects.\n\nThis workshop isn’t just about learning - it’s about transforming the way you interact with data. Whether you’re a beginner eager to dive into the world of programming or a seasoned professional looking to sharpen your skills, this workshop is designed to provide practical knowledge and hands-on experience that will set you apart.\nWe’re thrilled to have you join us and can’t wait to see the incredible things you’ll achieve with your new found skills in health data science using R. Let’s dive in and start this exciting journey together!"
  },
  {
    "objectID": "chatGPT.html",
    "href": "chatGPT.html",
    "title": "1 Advanced: Overview of AI tools and GitHub",
    "section": "",
    "text": "Source: ChatGPT. (2024, October 22). Integrating AI Tools for Data Science: A Guide for Healthcare Professionals. OpenAI. https://chat.openai.com/\n\n\nChatGPT is an AI tool that can assist with code writing, debugging, visualization, and problem-solving in R, especially when using the tidyverse package. By incorporating ChatGPT into your data analysis workflow, you can enhance productivity, improve code quality, and expedite the learning process. Below is a structured guide on how you can leverage ChatGPT effectively in your data science workflow.\n\n\n\nGenerate Code Templates: Ask ChatGPT to provide template code for tasks like data wrangling or visualization. Example: “How do I filter rows based on a column value in R using dplyr?”\nConvert Pseudocode to R Code: Write your logic in plain English, and ChatGPT can translate it into R code. Example: “Write R code to group data by state and calculate the mean of a numeric column.”\n\n\n\n\n\nTroubleshoot Errors: Share error messages with ChatGPT to get suggestions for fixes. Example: “I’m getting ‘Error: object not found’—how do I fix it?”\nOptimize Code: ChatGPT can suggest alternative, more efficient code using tidyverse functions. Example: “Is there a better way to combine multiple mutate statements?”\n\n\n\n\n\nCreate Plots from Scratch: Describe the data and desired visualization, and ChatGPT will generate the corresponding ggplot2 code. Example: “How do I create a scatter plot with color based on gender?”\nEnhance Visuals: Ask for improvements like changing themes, adding titles, or customizing colors. Example: “Improve the following bar plot by using a better theme and adding labels.”\nTroubleshoot ggplot Issues: If a plot isn’t displaying as expected, provide the code and ask for corrections. Example: “Why is my legend not showing up in this plot?”\n\n\n\n\n\nGet Help with Transformations: Explain your data structure and desired outcome to get tidyverse code for tasks like pivoting, grouping, or filtering. Example: “How do I reshape data from long to wide format?”\nCode Review: Paste your code for ChatGPT to review and improve readability or functionality. Example: “Can you simplify this chain of dplyr commands?”\n\n\n\n\n\nDiscover New Functions: Ask about specific packages or new functions that suit your needs. Example: “Is there an easier way to handle missing values in tidyverse?”\nUnderstand Code Snippets: If you encounter unfamiliar code, paste it and ask for an explanation. Example: “What does across() do in this code?”\n\n\n\n\n\nModeling with tidymodels: Get help building predictive models using tidymodels. Example: “How do I train a logistic regression model using tidymodels?”\nInterpreting Results: ChatGPT can assist in understanding output from statistical models. Example: “What does the p-value indicate in this summary?”\n\n\n\n\n\nBe Sensitive: The more details you provide about your problem, the better the solution. Example: “How do I calculate the weighted mean for a survey dataset using survey package in R?”\nIterate and Refine: If the initial response isn’t perfect, refine your query or ask for clarifications. Example: “Can you modify the code to include a facet grid by gender?”\nExplore Alternatives: Request multiple approaches to solve a problem or plot data differently. Example: “Can you show another way to visualize this data besides a bar plot?”\n\n\n\n\n\nGitHub is a platform for version control and collaboration using Git. It allows you to store code, track changes, and collaborate with others on data science projects. By integrating ChatGPT and GitHub into your workflow, healthcare professionals can efficiently develop, document, and collaborate on data science projects.\n\n\n\nCreate a New Repository: Log into GitHub and click New Repository.\nInitialize the Repo: Add a README.md and select whether to add .gitignore or a license.\nClone the Repository: Use the command below to copy the repository locally\n\n\n\n\n\nDocument Code Changes: Use ChatGPT to generate clear commit messages and update documentation.\nCollaborative Coding: Discuss coding challenges with ChatGPT and refine your GitHub project using suggestions.\nExperiment Safely: Use Git branches for experimentation and ask ChatGPT for guidance when working with complex code.\n\n\n\n\n\n\nChatGPT: General Code Assistance & Troubleshooting\nGitHub Copilot: AI for Code Completion\nGoogle Bard: AI for Information Retrieval and Research\nMicrosoft Excel Copilot: AI for Data Management\nAutoML Platforms (e.g., Google Cloud AutoML, H2O.ai)\nRStudio AI Features & Plugins"
  },
  {
    "objectID": "chatGPT.html#use-of-openai-chatgpt",
    "href": "chatGPT.html#use-of-openai-chatgpt",
    "title": "1 Advanced: Overview of AI tools and GitHub",
    "section": "",
    "text": "ChatGPT is an AI tool that can assist with code writing, debugging, visualization, and problem-solving in R, especially when using the tidyverse package. By incorporating ChatGPT into your data analysis workflow, you can enhance productivity, improve code quality, and expedite the learning process. Below is a structured guide on how you can leverage ChatGPT effectively in your data science workflow.\n\n\n\nGenerate Code Templates: Ask ChatGPT to provide template code for tasks like data wrangling or visualization. Example: “How do I filter rows based on a column value in R using dplyr?”\nConvert Pseudocode to R Code: Write your logic in plain English, and ChatGPT can translate it into R code. Example: “Write R code to group data by state and calculate the mean of a numeric column.”\n\n\n\n\n\nTroubleshoot Errors: Share error messages with ChatGPT to get suggestions for fixes. Example: “I’m getting ‘Error: object not found’—how do I fix it?”\nOptimize Code: ChatGPT can suggest alternative, more efficient code using tidyverse functions. Example: “Is there a better way to combine multiple mutate statements?”\n\n\n\n\n\nCreate Plots from Scratch: Describe the data and desired visualization, and ChatGPT will generate the corresponding ggplot2 code. Example: “How do I create a scatter plot with color based on gender?”\nEnhance Visuals: Ask for improvements like changing themes, adding titles, or customizing colors. Example: “Improve the following bar plot by using a better theme and adding labels.”\nTroubleshoot ggplot Issues: If a plot isn’t displaying as expected, provide the code and ask for corrections. Example: “Why is my legend not showing up in this plot?”\n\n\n\n\n\nGet Help with Transformations: Explain your data structure and desired outcome to get tidyverse code for tasks like pivoting, grouping, or filtering. Example: “How do I reshape data from long to wide format?”\nCode Review: Paste your code for ChatGPT to review and improve readability or functionality. Example: “Can you simplify this chain of dplyr commands?”\n\n\n\n\n\nDiscover New Functions: Ask about specific packages or new functions that suit your needs. Example: “Is there an easier way to handle missing values in tidyverse?”\nUnderstand Code Snippets: If you encounter unfamiliar code, paste it and ask for an explanation. Example: “What does across() do in this code?”\n\n\n\n\n\nModeling with tidymodels: Get help building predictive models using tidymodels. Example: “How do I train a logistic regression model using tidymodels?”\nInterpreting Results: ChatGPT can assist in understanding output from statistical models. Example: “What does the p-value indicate in this summary?”\n\n\n\n\n\nBe Sensitive: The more details you provide about your problem, the better the solution. Example: “How do I calculate the weighted mean for a survey dataset using survey package in R?”\nIterate and Refine: If the initial response isn’t perfect, refine your query or ask for clarifications. Example: “Can you modify the code to include a facet grid by gender?”\nExplore Alternatives: Request multiple approaches to solve a problem or plot data differently. Example: “Can you show another way to visualize this data besides a bar plot?”"
  },
  {
    "objectID": "chatGPT.html#use-of-github",
    "href": "chatGPT.html#use-of-github",
    "title": "1 Advanced: Overview of AI tools and GitHub",
    "section": "",
    "text": "GitHub is a platform for version control and collaboration using Git. It allows you to store code, track changes, and collaborate with others on data science projects. By integrating ChatGPT and GitHub into your workflow, healthcare professionals can efficiently develop, document, and collaborate on data science projects.\n\n\n\nCreate a New Repository: Log into GitHub and click New Repository.\nInitialize the Repo: Add a README.md and select whether to add .gitignore or a license.\nClone the Repository: Use the command below to copy the repository locally\n\n\n\n\n\nDocument Code Changes: Use ChatGPT to generate clear commit messages and update documentation.\nCollaborative Coding: Discuss coding challenges with ChatGPT and refine your GitHub project using suggestions.\nExperiment Safely: Use Git branches for experimentation and ask ChatGPT for guidance when working with complex code."
  },
  {
    "objectID": "chatGPT.html#using-ai-tools",
    "href": "chatGPT.html#using-ai-tools",
    "title": "1 Advanced: Overview of AI tools and GitHub",
    "section": "",
    "text": "ChatGPT: General Code Assistance & Troubleshooting\nGitHub Copilot: AI for Code Completion\nGoogle Bard: AI for Information Retrieval and Research\nMicrosoft Excel Copilot: AI for Data Management\nAutoML Platforms (e.g., Google Cloud AutoML, H2O.ai)\nRStudio AI Features & Plugins"
  },
  {
    "objectID": "additional.html",
    "href": "additional.html",
    "title": "1 Resource materials",
    "section": "",
    "text": "Grolemund, H., & Wickham, H. (2017). R for Data Science. O’Reilly Media. https://r4ds.had.co.nz/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning with Applications in R. Springer. https://www.statlearning.com/\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer. https://ggplot2-book.org/\nVenables, W. N., & Ripley, B. D. (2002). Modern Applied Statistics with S (4th ed.). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\nPeng, R. D. (2015). R Programming for Data Science. Leanpub. https://bookdown.org/rdpeng/rprogdatascience/\nKuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer. https://topepo.github.io/caret/\nMcKinney, W. (2017). Python for Data Analysis (2nd ed.). O’Reilly Media. https://www.oreilly.com/library/view/python-for-data/9781491957653/ [Note: While this book focuses on Python, it offers valuable insights into data manipulation and analysis that are transferable to R.]\n\n\n\n\n\nggplot2 Gallery: https://exts.ggplot2.tidyverse.org/gallery/\nR Graphics Cookbook: https://r-graphics.org/\nTidyverse Course: https://jhudatascience.org/tidyversecourse/get-data.html\nTidyverse Cookbook: https://rstudio-education.github.io/tidyverse-cookbook/import.html\nData Wrangling Cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\nR Markdown: The Definitive Guide: https://bookdown.org/yihui/rmarkdown/\nQuarto: https://quarto.org/"
  },
  {
    "objectID": "additional.html#additional-readings",
    "href": "additional.html#additional-readings",
    "title": "1 Resource materials",
    "section": "",
    "text": "Grolemund, H., & Wickham, H. (2017). R for Data Science. O’Reilly Media. https://r4ds.had.co.nz/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). An Introduction to Statistical Learning with Applications in R. Springer. https://www.statlearning.com/\nWickham, H. (2016). ggplot2: Elegant Graphics for Data Analysis. Springer. https://ggplot2-book.org/\nVenables, W. N., & Ripley, B. D. (2002). Modern Applied Statistics with S (4th ed.). Springer. https://www.stats.ox.ac.uk/pub/MASS4/\nPeng, R. D. (2015). R Programming for Data Science. Leanpub. https://bookdown.org/rdpeng/rprogdatascience/\nKuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer. https://topepo.github.io/caret/\nMcKinney, W. (2017). Python for Data Analysis (2nd ed.). O’Reilly Media. https://www.oreilly.com/library/view/python-for-data/9781491957653/ [Note: While this book focuses on Python, it offers valuable insights into data manipulation and analysis that are transferable to R.]"
  },
  {
    "objectID": "additional.html#additional-resources",
    "href": "additional.html#additional-resources",
    "title": "1 Resource materials",
    "section": "",
    "text": "ggplot2 Gallery: https://exts.ggplot2.tidyverse.org/gallery/\nR Graphics Cookbook: https://r-graphics.org/\nTidyverse Course: https://jhudatascience.org/tidyversecourse/get-data.html\nTidyverse Cookbook: https://rstudio-education.github.io/tidyverse-cookbook/import.html\nData Wrangling Cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf\nR Markdown: The Definitive Guide: https://bookdown.org/yihui/rmarkdown/\nQuarto: https://quarto.org/"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "Exploratory Data Analysis or EDA is the critical process of performing initial investigations on data to discover patterns, spot anomalies, test hypotheses and check assumptions with the help of summary statistics and graphical representations.\nThe major objective of this session is to teach participants on basics of exploring datasets and develop an understanding about the datasets using descriptive statistics and summary tables. In the next session, we shall explore visualization methods.\n\n\n\nAs in the previous session, lets look at some summary statistics using summary() function.\n\n\nCode\ndf |&gt; summary()\n\n\n         child_weight_cat  maternal_age   maternal_weight      race      \n Normal          :130     Min.   :14.00   Min.   : 80.0   Min.   :1.000  \n Low Birth Weight: 59     1st Qu.:19.00   1st Qu.:110.0   1st Qu.:1.000  \n                          Median :23.00   Median :121.0   Median :1.000  \n                          Mean   :23.24   Mean   :129.8   Mean   :1.847  \n                          3rd Qu.:26.00   3rd Qu.:140.0   3rd Qu.:3.000  \n                          Max.   :45.00   Max.   :250.0   Max.   :3.000  \n     smoke        number_preterm    hypertension     uterine_irritability\n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000      \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000      \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000      \n Mean   :0.3915   Mean   :0.1958   Mean   :0.06349   Mean   :0.1481      \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000      \n Max.   :1.0000   Max.   :3.0000   Max.   :1.00000   Max.   :1.0000      \n health_visits     birth_weight       smoke_cat    race_cat \n Min.   :0.0000   Min.   : 709   Non-smoker:115   White:96  \n 1st Qu.:0.0000   1st Qu.:2414   Smoker    : 74   Black:26  \n Median :0.0000   Median :2977                    Other:67  \n Mean   :0.7937   Mean   :2945                              \n 3rd Qu.:1.0000   3rd Qu.:3487                              \n Max.   :6.0000   Max.   :4990                              \n\n\n\n\n\nsummarise() function helps in obtaining summary statistics. The output has a summary statistics as asked within this function. In this example, we have used mean and sd functions for the same.\n\n\nCode\ndf |&gt; \n  select(maternal_age) |&gt; \n  summarise(mean_age = mean(maternal_age),\n            sd_age = sd(maternal_age))\n\n\n# A tibble: 1 × 2\n  mean_age sd_age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     23.2   5.30\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThough we were able to get the summary statistics, in routine, it is very time consuming, frustrating and error prone to write again the results/ outputs obtained from statistical software into the writing and communication documents, be it an article/ manuscript or a dissertation or a thesis. In R, there are certain packages which enable you to create publication ready tables which can be incorporated into research dissemination documents directly or with minor modifications. This saves a lot of mundane and unnecessary work and provides more time for interpretation and domain expertise related work. gtsummary package creates presentation-ready tables summarizing data sets, regression models, and more. The code to create the tables is concise and highly customizable.\n\n\n\n\n\nThe tbl_summary() function calculates descriptive statistics for continuous, categorical, and dichotomous variables in R, and presents the results in a beautiful, customizable summary table ready for publication. To introduce tbl_summary() we will show the most basic behaviour first, which actually produces a large and beautiful table. Then, we will examine in detail how to make adjustments and more tailored tables.The default behavior of tbl_summary() is quite incredible - it takes the columns you provide and creates a summary table in one command. The function prints statistics appropriate to the column class: median and inter-quartile range (IQR) for numeric columns, and counts (%) for categorical columns. Missing values are converted to ‘Unknown’.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary()\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.0 (19.0, 26.0)\n\n\nmaternal_weight\n121 (110, 140)\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\n\nUse equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the columns to which that display will apply.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = maternal_age ~ \"{mean}, {sd}\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nmaternal_weight\n121 (110, 140)\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the list of columns to which that display will apply.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nmaternal_weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjust how the column name should be displayed. Provide the column name and its desired label separated by a tilde. The default is the column name. This is done with help of argument label = in tbl_summary function.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = maternal_weight ~ \"Maternal Weight\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nMaternal Weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can change labels of multiple variables by providing the labels as a list to the label argument.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\")\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nMaternal Age\n23.2, 5.3\n\n\nMaternal Weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = race_cat\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nWhite, N = 961\nBlack, N = 261\nOther, N = 671\n\n\n\n\nMaternal Age\n24.3, 5.7\n21.5, 5.1\n22.4, 4.5\n\n\nMaternal Weight\n132, 29\n147, 40\n120, 25\n\n\nSmoking History\n\n\n\n\n\n    Non-smoker\n44 (46%)\n16 (62%)\n55 (82%)\n\n\n    Smoker\n52 (54%)\n10 (38%)\n12 (18%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this session, we looked at summarise function and basics of gtsummary’s tbl_summary function for EDA. We shall be using these basic concepts further during the analysis in subsequent sessions."
  },
  {
    "objectID": "eda.html#introduction",
    "href": "eda.html#introduction",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "Exploratory Data Analysis or EDA is the critical process of performing initial investigations on data to discover patterns, spot anomalies, test hypotheses and check assumptions with the help of summary statistics and graphical representations.\nThe major objective of this session is to teach participants on basics of exploring datasets and develop an understanding about the datasets using descriptive statistics and summary tables. In the next session, we shall explore visualization methods."
  },
  {
    "objectID": "eda.html#descriptive-statistics",
    "href": "eda.html#descriptive-statistics",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "As in the previous session, lets look at some summary statistics using summary() function.\n\n\nCode\ndf |&gt; summary()\n\n\n         child_weight_cat  maternal_age   maternal_weight      race      \n Normal          :130     Min.   :14.00   Min.   : 80.0   Min.   :1.000  \n Low Birth Weight: 59     1st Qu.:19.00   1st Qu.:110.0   1st Qu.:1.000  \n                          Median :23.00   Median :121.0   Median :1.000  \n                          Mean   :23.24   Mean   :129.8   Mean   :1.847  \n                          3rd Qu.:26.00   3rd Qu.:140.0   3rd Qu.:3.000  \n                          Max.   :45.00   Max.   :250.0   Max.   :3.000  \n     smoke        number_preterm    hypertension     uterine_irritability\n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000      \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000      \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000      \n Mean   :0.3915   Mean   :0.1958   Mean   :0.06349   Mean   :0.1481      \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000      \n Max.   :1.0000   Max.   :3.0000   Max.   :1.00000   Max.   :1.0000      \n health_visits     birth_weight       smoke_cat    race_cat \n Min.   :0.0000   Min.   : 709   Non-smoker:115   White:96  \n 1st Qu.:0.0000   1st Qu.:2414   Smoker    : 74   Black:26  \n Median :0.0000   Median :2977                    Other:67  \n Mean   :0.7937   Mean   :2945                              \n 3rd Qu.:1.0000   3rd Qu.:3487                              \n Max.   :6.0000   Max.   :4990"
  },
  {
    "objectID": "eda.html#calculating-mean-and-sd-of-maternal-age.",
    "href": "eda.html#calculating-mean-and-sd-of-maternal-age.",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "summarise() function helps in obtaining summary statistics. The output has a summary statistics as asked within this function. In this example, we have used mean and sd functions for the same.\n\n\nCode\ndf |&gt; \n  select(maternal_age) |&gt; \n  summarise(mean_age = mean(maternal_age),\n            sd_age = sd(maternal_age))\n\n\n# A tibble: 1 × 2\n  mean_age sd_age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     23.2   5.30"
  },
  {
    "objectID": "eda.html#presentation-tables-for-descriptive-statistics",
    "href": "eda.html#presentation-tables-for-descriptive-statistics",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "Important\n\n\n\nThough we were able to get the summary statistics, in routine, it is very time consuming, frustrating and error prone to write again the results/ outputs obtained from statistical software into the writing and communication documents, be it an article/ manuscript or a dissertation or a thesis. In R, there are certain packages which enable you to create publication ready tables which can be incorporated into research dissemination documents directly or with minor modifications. This saves a lot of mundane and unnecessary work and provides more time for interpretation and domain expertise related work. gtsummary package creates presentation-ready tables summarizing data sets, regression models, and more. The code to create the tables is concise and highly customizable."
  },
  {
    "objectID": "eda.html#maternal-characteristics-an-illustrative-example.",
    "href": "eda.html#maternal-characteristics-an-illustrative-example.",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "The tbl_summary() function calculates descriptive statistics for continuous, categorical, and dichotomous variables in R, and presents the results in a beautiful, customizable summary table ready for publication. To introduce tbl_summary() we will show the most basic behaviour first, which actually produces a large and beautiful table. Then, we will examine in detail how to make adjustments and more tailored tables.The default behavior of tbl_summary() is quite incredible - it takes the columns you provide and creates a summary table in one command. The function prints statistics appropriate to the column class: median and inter-quartile range (IQR) for numeric columns, and counts (%) for categorical columns. Missing values are converted to ‘Unknown’.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary()\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.0 (19.0, 26.0)\n\n\nmaternal_weight\n121 (110, 140)\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\n\nUse equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the columns to which that display will apply.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = maternal_age ~ \"{mean}, {sd}\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nmaternal_weight\n121 (110, 140)\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; Median (IQR); n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse equations to specify which statistics to show and how to display them. There are two sides to the equation, separated by a tilde ~. On the right side, in quotes, is the statistical display desired, and on the left are the list of columns to which that display will apply.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nmaternal_weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdjust how the column name should be displayed. Provide the column name and its desired label separated by a tilde. The default is the column name. This is done with help of argument label = in tbl_summary function.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = maternal_weight ~ \"Maternal Weight\"\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nmaternal_age\n23.2, 5.3\n\n\nMaternal Weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can change labels of multiple variables by providing the labels as a list to the label argument.\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\")\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nN = 1891\n\n\n\n\nMaternal Age\n23.2, 5.3\n\n\nMaternal Weight\n130, 31\n\n\nrace_cat\n\n\n\n    White\n96 (51%)\n\n\n    Black\n26 (14%)\n\n\n    Other\n67 (35%)\n\n\nsmoke_cat\n\n\n\n    Non-smoker\n115 (61%)\n\n\n    Smoker\n74 (39%)\n\n\n\n1 Mean, SD; n (%)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(maternal_age, maternal_weight,\n         race_cat, smoke_cat) |&gt; \n  tbl_summary(\n    statistic = all_continuous() ~ \"{mean}, {sd}\",\n    label = list(maternal_weight ~ \"Maternal Weight\",\n                 maternal_age ~ \"Maternal Age\",\n                 smoke_cat ~ \"Smoking History\"),\n    by = race_cat\n  )\n\n\n\n\n\n\n\n\nCharacteristic\nWhite, N = 961\nBlack, N = 261\nOther, N = 671\n\n\n\n\nMaternal Age\n24.3, 5.7\n21.5, 5.1\n22.4, 4.5\n\n\nMaternal Weight\n132, 29\n147, 40\n120, 25\n\n\nSmoking History\n\n\n\n\n\n    Non-smoker\n44 (46%)\n16 (62%)\n55 (82%)\n\n\n    Smoker\n52 (54%)\n10 (38%)\n12 (18%)\n\n\n\n1 Mean, SD; n (%)"
  },
  {
    "objectID": "eda.html#summary.",
    "href": "eda.html#summary.",
    "title": "1 Exploratory Data Analysis (Descriptive statistics)",
    "section": "",
    "text": "In this session, we looked at summarise function and basics of gtsummary’s tbl_summary function for EDA. We shall be using these basic concepts further during the analysis in subsequent sessions."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "Tip\n\n\n\nInstall R\n\nGo here: https://cran.rstudio.com/\nChoose the correct “Download R for. . .” option from the top (probably Windows or macOS), then…\n\nIf it installs, you should be able to find the R icon in your applications.\n\n\n\n\nOpen source (free!) statistical programming language/software\nIt can be used for:\n\nWorking with data - cleaning, wrangling and transforming\nConducting analyses including advanced statistical methods\nCreating high-quality tables & figures\nCommunicate research with R Markdown\n\nIt is constantly growing!\nHas a strong online support community\nSince it’s one programming language, it is versatile enough to take you from raw data to publishable research using free, reproducible code!\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nInstall RStudio\nGo to https://www.rstudio.com/products/rstudio/download/ to download RStudio Desktop (Open Source License).\nIf it installs, you should be able to find the RStudio icon in your applications.\n\n\n\nRStudio is a free, open source IDE (integrated development environment) for R. (You must install R before you can install RStudio.)\nIts interface is organized so that the user can clearly view graphs, tables, R code, and output all at the same time.\nIt also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SPSS (*.sav), and Stata (*.dta) files into R without having to write the code to do so.\n\n\n\n\nR is becoming the “lingua franca” of data science\nMost widely used and it is rising in popularity\nR is also the tool of choice for data scientists at Microsoft, Google, Facebook, Amazon\nR’s popularity in academia is important because that creates a pool of talent that feeds industry.\nLearning the “skills of data science” is easiest in R\n\n\n\nExcel and SPSS are convenient for data entry, and for quickly manipulating rows and columns prior to statistical analysis.\nHowever, they are a poor choice for statistical analysis beyond the simplest descriptive statistics, or for more than a very few columns.\nSome of the reasons for choosing R over others are are:\n\nMissing values are handled inconsistently, and sometimes incorrectly.\nData organisation difficult.\nAnalyses can only be done on one column at a time.\nOutput is poorly organised.\nNo record of how an analysis was accomplished.\nSome advanced analyses are impossible\n\n\n\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator.\n\n\n\n\n\n\n\n\nNote\n\n\n\nReproducibility is a minimum necessary condition for a finding to be believable and informative. - U.S. National Science Foundation (NSF) subcommittee\n\n\nThat is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results.\n\n\n\n\nNot enough documentation on how experiment is conducted and data is generated\nData used to generate original results unavailable\nSoftware used to generate original results unavailable\nDifficult to recreate software environment (libraries, versions) used to generate original results\nDifficult to rerun the computational steps\n\n\n\n\n\n\n\n\n\n\n\n\n\nThree Rules of Tidy Data\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\nTidy data is a way to describe data that’s organized with a particular structure – a rectangular structure, where each variable has its own column, and each observation has its own row…………Hadley Wickham, 2014\n\n\n\n\n\nThe RStudio environment consist of multiple windows. Each window consist of certain Panels which includes:\n\n\n\nSource\n\nConsole\n\nEnvironment\n\nHistory\nFiles\nPlots\n\nConnections\n\nPackages\n\nHelp\n\nBuild\n\nVCS\n\nTutorial\n\nViewer\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to understand that not all panels will be used by you in routine as well as by us during the workshop. The workshop focuses on using R for healthcare professionals as a database management, visualization, and communication tool. The most common panels which requires attention are the source, console, environment, history, files, packages, help, tutorial, and viewer panels.\n\n\n\n\n\n\n\n\n\n\n\n\nA guided tour\n\n\n\nYou are requested to make your own notes during the workshop. Let us dive deep into understanding the environment further in the workshop.\n\n\n\n\n\n\nIt is important to understand that good workflows facilitate efficient database management. Lets discuss!\n\n\n\nThe most common used file types are\n\n.R : Script file.\n\n.qmd: Quarto Markdown file.\n\n.rds: Single R database file.\n\n.Rproj: R Project file.\n\n\n\n\nR is easiest to use when you know how the R language works. This section will teach you the implicit background knowledge that informs every piece of R code. You’ll learn about:\n\nFunctions and their arguments.\n\nObjects.\n\nR’s basic data types.\n\nR’s basic data structures including vectors and lists.\n\nR’s package system.\n\n\n\nTo do anything in R, we call functions to work for us. Take for example, we want to compute square root of 5197. Now, we need to call a function sqrt() for the same.\n\n\n\nsqrt(5197)\n\n\n\n\n[1] 72.09022\n\n\n\n\nImportant things to know about functions include:\n\nCode body.\n\n\nsqrt\n\nfunction (x)  .Primitive(\"sqrt\")\n\n\nTyping code body and running it enables us understand what a function does in background.\n\nRun a function.\n\nTo run a function, we need to add a parenthesis \\(()\\) after the code body.Within the parenthesis we add the details such as number in the above example.\n\nHelp page.\n\nPlacing a question mark before the function takes you to the help page. This is the most important aspect we need to understand. When calling help page parenthesis is not placed. This help page will enable you learn about new functions in your journey!\n\n\nCode\n# ?sqrt \n# Tip: Annotations: Annotations are meant for humans to read and not by machines. It enables us take notes as we write. As a result, next time when you open your code even after a long time, you will know what you did last summer :)\n\n\nArguments are inputs provided to the function. There are functions which take no arguments, some take a single argument and some take multiple arguments. When there are two or more arguments, the arguments are separated by a comma.\n\n# No argument\nSys.Date()\n\n[1] \"2024-10-22\"\n\n# One argument\nsqrt(5197)\n\n[1] 72.09022\n\n# Two arguments\nsum(2,3)\n\n[1] 5\n\n# Multiple arguments\nseq(from=1,\n    to = 10, \n    by  = 2)\n\n[1] 1 3 5 7 9\n\n\nMatching arguments: Some arguments are understood as such by the software. Take for example, generating a sequence includes three arguments viz: from, to, by. The right inputs are automatically matched to the right argument.\n\nseq(1,10,2)\n\n[1] 1 3 5 7 9\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe wrong inputs are also matched. Best practice is to be explicit at early stages. Use argument names!\n\n\n\nseq(2,10,1)\n\n[1]  2  3  4  5  6  7  8  9 10\n\nseq(by = 2,\n    to = 10,\n    from = 1)\n\n[1] 1 3 5 7 9\n\n\nOptional arguments: Some arguments are optional. They may be added or removed as per requirement. By default these optional arguments are taken by R as default values. Take for example, in sum() function, na.rm = FALSE is an optional argument. It ensures that the NA values are not removed by default and the sum is not returned when there are NA values. These optional arguments can be override by mentioning them explicitly.\n\nsum(2,3,NA)\n\n[1] NA\n\nsum(2,3,NA, na.rm = T)\n\n[1] 5\n\n\nIn contrast, the arguments which needs to be mentioned explicitly are mandatory! Without them, errors are returned as output.\n\nsqrt()\n\n\n\n\nIf we want to use the results in addition to viewing them in console, we need to store them as objects. To create an object, type the name of the object (Choose wisely, let it be explicit and self explanatory!), then provide an assignment operator. Everything to the right of the operator will be assigned to the object. You can save a single value or output of a function or multiple values or an entire data set in a single object.\n\n# Single value\nx &lt;- 3\nx\n\n[1] 3\n\n# Output from function\nx &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n# Better name:\nsequence_from_1_to_10 &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n\nCreating an object helps us in viewing its contents as well make it easier to apply additional functions\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhile typing functions/ object names, R prompts are provided. Choose from the prompts rather than typing the entire thing. It will ease out many things later!\n\n\n\nsequence_from_1_to_10\n\n[1] 1 3 5 7 9\n\nsum(sequence_from_1_to_10)\n\n[1] 25\n\n\n\n\nR stores values as a vector which is one dimensional array. Arrays can be two dimensional (similar to excel data/ tabular data), or multidimensional. Vectors are always one dimensional!\nVectors can be a single value or a combination of values. We can create our own vectors using c() function.\n\nsingle_number &lt;- 3\nsingle_number\n\n[1] 3\n\nnumber_vector &lt;- c(1,2,3)\nnumber_vector\n\n[1] 1 2 3\n\n\nCreating personalized vectors is powerful as a lot of functions in R takes vectors as inputs.\n\nmean(number_vector)\n\n[1] 2\n\n\nVectorized functions: The function is applied to each element of the vector:\n\nsqrt(number_vector)\n\n[1] 1.000000 1.414214 1.732051\n\n\nIf we have two vectors of similar lengths (such as columns of a research data), vectorised functions help us compute for new columns by applying the said function on each element of both the vectors and give a vector of the same length (Consider this as a new column in the research data)\n\nnumber_vector2 &lt;- c(3,-4,5.4)\nnumber_vector + number_vector2\n\n[1]  4.0 -2.0  8.4\n\n\n\n\n\nR recognizes different types of vectors based on the values in the vector.\nIf all values are numbers (positive numbers, negative numbers, decimals), R will consider that vector as numerical and allows you to carry out mathematical operations/ functions. You can find the class of the vector by using class() function.R labels these vectors as “double”, “numeric”, or “integers”.\n\nclass(number_vector)\n\n[1] \"numeric\"\n\nclass(number_vector2)\n\n[1] \"numeric\"\n\n\nIf the values are within quotation marks, it is character variable by default. It is equivalent to nominal variable.\n\nalphabets_vector &lt;- c(\"a\", \"b\", \"c\")\nclass(alphabets_vector)\n\n[1] \"character\"\n\ninteger_vector &lt;- c(1L,2L)\nclass(integer_vector)\n\n[1] \"integer\"\n\n\nLogical vectors contain TRUE and FALSE values\n\nlogical_vector &lt;- c(TRUE, FALSE)\nclass(logical_vector)\n\n[1] \"logical\"\n\n\nOne vector = One type. For example: When there is mix of numbers and characters, R will consider all as character.\n\nmix_vector &lt;- c(1,\"a\")\nclass(mix_vector)\n\n[1] \"character\"\n\n\nDouble, character, integer, logical, complex, raw, dates, etc… There are many other data types and objects but for now, lets start with these. You will understand additional types as you will proceed in your R journey!\n\n\n\nIn addition to vectors, lists are another powerful objects. A list can be considered as a vector of vectors!! They enable you to store multiple types of vectors together. A list can be made using a list() function. It is similar to c() function but creates a list rather than a vector. It is a good practice to name the vectors in the list.\n\nexample_list &lt;- list(numbers = number_vector, \n                     alphabets = alphabets_vector)\nclass(example_list)\n\n[1] \"list\"\n\nexample_list\n\n$numbers\n[1] 1 2 3\n\n$alphabets\n[1] \"a\" \"b\" \"c\"\n\n\nThe elements of a named list/ a named vector can be called by using a $.\n\nexample_list$numbers\n\n[1] 1 2 3\n\n\nImportant: Dataframes/ excelsheet we use are special type of lists. Each column is named and is a vector!!\n\n\n\nThere are thousands of functions in R. To be computationally efficient, R do not load all functions on start. It loads only base functions. As you want to use additional functions, we need to load the packages using library() function.\nImportant: The additional packages are installed once but loaded everytime you start R sessions."
  },
  {
    "objectID": "intro.html#what-is-r",
    "href": "intro.html#what-is-r",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "Tip\n\n\n\nInstall R\n\nGo here: https://cran.rstudio.com/\nChoose the correct “Download R for. . .” option from the top (probably Windows or macOS), then…\n\nIf it installs, you should be able to find the R icon in your applications.\n\n\n\n\nOpen source (free!) statistical programming language/software\nIt can be used for:\n\nWorking with data - cleaning, wrangling and transforming\nConducting analyses including advanced statistical methods\nCreating high-quality tables & figures\nCommunicate research with R Markdown\n\nIt is constantly growing!\nHas a strong online support community\nSince it’s one programming language, it is versatile enough to take you from raw data to publishable research using free, reproducible code!"
  },
  {
    "objectID": "intro.html#what-is-rstudio",
    "href": "intro.html#what-is-rstudio",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "Tip\n\n\n\nInstall RStudio\nGo to https://www.rstudio.com/products/rstudio/download/ to download RStudio Desktop (Open Source License).\nIf it installs, you should be able to find the RStudio icon in your applications.\n\n\n\nRStudio is a free, open source IDE (integrated development environment) for R. (You must install R before you can install RStudio.)\nIts interface is organized so that the user can clearly view graphs, tables, R code, and output all at the same time.\nIt also offers an Import-Wizard-like feature that allows users to import CSV, Excel, SPSS (*.sav), and Stata (*.dta) files into R without having to write the code to do so."
  },
  {
    "objectID": "intro.html#why-should-you-learn-r",
    "href": "intro.html#why-should-you-learn-r",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "R is becoming the “lingua franca” of data science\nMost widely used and it is rising in popularity\nR is also the tool of choice for data scientists at Microsoft, Google, Facebook, Amazon\nR’s popularity in academia is important because that creates a pool of talent that feeds industry.\nLearning the “skills of data science” is easiest in R\n\n\n\nExcel and SPSS are convenient for data entry, and for quickly manipulating rows and columns prior to statistical analysis.\nHowever, they are a poor choice for statistical analysis beyond the simplest descriptive statistics, or for more than a very few columns.\nSome of the reasons for choosing R over others are are:\n\nMissing values are handled inconsistently, and sometimes incorrectly.\nData organisation difficult.\nAnalyses can only be done on one column at a time.\nOutput is poorly organised.\nNo record of how an analysis was accomplished.\nSome advanced analyses are impossible\n\n\n\n\nReproducibility refers to the ability of a researcher to duplicate the results of a prior study using the same materials as were used by the original investigator.\n\n\n\n\n\n\n\n\nNote\n\n\n\nReproducibility is a minimum necessary condition for a finding to be believable and informative. - U.S. National Science Foundation (NSF) subcommittee\n\n\nThat is, a second researcher might use the same raw data to build the same analysis files and implement the same statistical analysis in an attempt to yield the same results.\n\n\n\n\nNot enough documentation on how experiment is conducted and data is generated\nData used to generate original results unavailable\nSoftware used to generate original results unavailable\nDifficult to recreate software environment (libraries, versions) used to generate original results\nDifficult to rerun the computational steps"
  },
  {
    "objectID": "intro.html#what-is-tidy-data",
    "href": "intro.html#what-is-tidy-data",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "Three Rules of Tidy Data\n\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\nTidy data is a way to describe data that’s organized with a particular structure – a rectangular structure, where each variable has its own column, and each observation has its own row…………Hadley Wickham, 2014"
  },
  {
    "objectID": "intro.html#understanding-the-rstudio-environment",
    "href": "intro.html#understanding-the-rstudio-environment",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "The RStudio environment consist of multiple windows. Each window consist of certain Panels which includes:\n\n\n\nSource\n\nConsole\n\nEnvironment\n\nHistory\nFiles\nPlots\n\nConnections\n\nPackages\n\nHelp\n\nBuild\n\nVCS\n\nTutorial\n\nViewer\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to understand that not all panels will be used by you in routine as well as by us during the workshop. The workshop focuses on using R for healthcare professionals as a database management, visualization, and communication tool. The most common panels which requires attention are the source, console, environment, history, files, packages, help, tutorial, and viewer panels.\n\n\n\n\n\n\n\n\n\n\n\n\nA guided tour\n\n\n\nYou are requested to make your own notes during the workshop. Let us dive deep into understanding the environment further in the workshop."
  },
  {
    "objectID": "intro.html#creating-a-project.",
    "href": "intro.html#creating-a-project.",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "It is important to understand that good workflows facilitate efficient database management. Lets discuss!"
  },
  {
    "objectID": "intro.html#file-types-in-r.",
    "href": "intro.html#file-types-in-r.",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "The most common used file types are\n\n.R : Script file.\n\n.qmd: Quarto Markdown file.\n\n.rds: Single R database file.\n\n.Rproj: R Project file."
  },
  {
    "objectID": "intro.html#programming-basics.",
    "href": "intro.html#programming-basics.",
    "title": "1 Introduction to R and RStudio",
    "section": "",
    "text": "R is easiest to use when you know how the R language works. This section will teach you the implicit background knowledge that informs every piece of R code. You’ll learn about:\n\nFunctions and their arguments.\n\nObjects.\n\nR’s basic data types.\n\nR’s basic data structures including vectors and lists.\n\nR’s package system.\n\n\n\nTo do anything in R, we call functions to work for us. Take for example, we want to compute square root of 5197. Now, we need to call a function sqrt() for the same.\n\n\n\nsqrt(5197)\n\n\n\n\n[1] 72.09022\n\n\n\n\nImportant things to know about functions include:\n\nCode body.\n\n\nsqrt\n\nfunction (x)  .Primitive(\"sqrt\")\n\n\nTyping code body and running it enables us understand what a function does in background.\n\nRun a function.\n\nTo run a function, we need to add a parenthesis \\(()\\) after the code body.Within the parenthesis we add the details such as number in the above example.\n\nHelp page.\n\nPlacing a question mark before the function takes you to the help page. This is the most important aspect we need to understand. When calling help page parenthesis is not placed. This help page will enable you learn about new functions in your journey!\n\n\nCode\n# ?sqrt \n# Tip: Annotations: Annotations are meant for humans to read and not by machines. It enables us take notes as we write. As a result, next time when you open your code even after a long time, you will know what you did last summer :)\n\n\nArguments are inputs provided to the function. There are functions which take no arguments, some take a single argument and some take multiple arguments. When there are two or more arguments, the arguments are separated by a comma.\n\n# No argument\nSys.Date()\n\n[1] \"2024-10-22\"\n\n# One argument\nsqrt(5197)\n\n[1] 72.09022\n\n# Two arguments\nsum(2,3)\n\n[1] 5\n\n# Multiple arguments\nseq(from=1,\n    to = 10, \n    by  = 2)\n\n[1] 1 3 5 7 9\n\n\nMatching arguments: Some arguments are understood as such by the software. Take for example, generating a sequence includes three arguments viz: from, to, by. The right inputs are automatically matched to the right argument.\n\nseq(1,10,2)\n\n[1] 1 3 5 7 9\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe wrong inputs are also matched. Best practice is to be explicit at early stages. Use argument names!\n\n\n\nseq(2,10,1)\n\n[1]  2  3  4  5  6  7  8  9 10\n\nseq(by = 2,\n    to = 10,\n    from = 1)\n\n[1] 1 3 5 7 9\n\n\nOptional arguments: Some arguments are optional. They may be added or removed as per requirement. By default these optional arguments are taken by R as default values. Take for example, in sum() function, na.rm = FALSE is an optional argument. It ensures that the NA values are not removed by default and the sum is not returned when there are NA values. These optional arguments can be override by mentioning them explicitly.\n\nsum(2,3,NA)\n\n[1] NA\n\nsum(2,3,NA, na.rm = T)\n\n[1] 5\n\n\nIn contrast, the arguments which needs to be mentioned explicitly are mandatory! Without them, errors are returned as output.\n\nsqrt()\n\n\n\n\nIf we want to use the results in addition to viewing them in console, we need to store them as objects. To create an object, type the name of the object (Choose wisely, let it be explicit and self explanatory!), then provide an assignment operator. Everything to the right of the operator will be assigned to the object. You can save a single value or output of a function or multiple values or an entire data set in a single object.\n\n# Single value\nx &lt;- 3\nx\n\n[1] 3\n\n# Output from function\nx &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n# Better name:\nsequence_from_1_to_10 &lt;- seq(from=1,\n    to = 10, \n    by  = 2)\n\nCreating an object helps us in viewing its contents as well make it easier to apply additional functions\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhile typing functions/ object names, R prompts are provided. Choose from the prompts rather than typing the entire thing. It will ease out many things later!\n\n\n\nsequence_from_1_to_10\n\n[1] 1 3 5 7 9\n\nsum(sequence_from_1_to_10)\n\n[1] 25\n\n\n\n\nR stores values as a vector which is one dimensional array. Arrays can be two dimensional (similar to excel data/ tabular data), or multidimensional. Vectors are always one dimensional!\nVectors can be a single value or a combination of values. We can create our own vectors using c() function.\n\nsingle_number &lt;- 3\nsingle_number\n\n[1] 3\n\nnumber_vector &lt;- c(1,2,3)\nnumber_vector\n\n[1] 1 2 3\n\n\nCreating personalized vectors is powerful as a lot of functions in R takes vectors as inputs.\n\nmean(number_vector)\n\n[1] 2\n\n\nVectorized functions: The function is applied to each element of the vector:\n\nsqrt(number_vector)\n\n[1] 1.000000 1.414214 1.732051\n\n\nIf we have two vectors of similar lengths (such as columns of a research data), vectorised functions help us compute for new columns by applying the said function on each element of both the vectors and give a vector of the same length (Consider this as a new column in the research data)\n\nnumber_vector2 &lt;- c(3,-4,5.4)\nnumber_vector + number_vector2\n\n[1]  4.0 -2.0  8.4\n\n\n\n\n\nR recognizes different types of vectors based on the values in the vector.\nIf all values are numbers (positive numbers, negative numbers, decimals), R will consider that vector as numerical and allows you to carry out mathematical operations/ functions. You can find the class of the vector by using class() function.R labels these vectors as “double”, “numeric”, or “integers”.\n\nclass(number_vector)\n\n[1] \"numeric\"\n\nclass(number_vector2)\n\n[1] \"numeric\"\n\n\nIf the values are within quotation marks, it is character variable by default. It is equivalent to nominal variable.\n\nalphabets_vector &lt;- c(\"a\", \"b\", \"c\")\nclass(alphabets_vector)\n\n[1] \"character\"\n\ninteger_vector &lt;- c(1L,2L)\nclass(integer_vector)\n\n[1] \"integer\"\n\n\nLogical vectors contain TRUE and FALSE values\n\nlogical_vector &lt;- c(TRUE, FALSE)\nclass(logical_vector)\n\n[1] \"logical\"\n\n\nOne vector = One type. For example: When there is mix of numbers and characters, R will consider all as character.\n\nmix_vector &lt;- c(1,\"a\")\nclass(mix_vector)\n\n[1] \"character\"\n\n\nDouble, character, integer, logical, complex, raw, dates, etc… There are many other data types and objects but for now, lets start with these. You will understand additional types as you will proceed in your R journey!\n\n\n\nIn addition to vectors, lists are another powerful objects. A list can be considered as a vector of vectors!! They enable you to store multiple types of vectors together. A list can be made using a list() function. It is similar to c() function but creates a list rather than a vector. It is a good practice to name the vectors in the list.\n\nexample_list &lt;- list(numbers = number_vector, \n                     alphabets = alphabets_vector)\nclass(example_list)\n\n[1] \"list\"\n\nexample_list\n\n$numbers\n[1] 1 2 3\n\n$alphabets\n[1] \"a\" \"b\" \"c\"\n\n\nThe elements of a named list/ a named vector can be called by using a $.\n\nexample_list$numbers\n\n[1] 1 2 3\n\n\nImportant: Dataframes/ excelsheet we use are special type of lists. Each column is named and is a vector!!\n\n\n\nThere are thousands of functions in R. To be computationally efficient, R do not load all functions on start. It loads only base functions. As you want to use additional functions, we need to load the packages using library() function.\nImportant: The additional packages are installed once but loaded everytime you start R sessions."
  },
  {
    "objectID": "understand_wrangle.html",
    "href": "understand_wrangle.html",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "We will be introducing birthwt dataset from the MASS package which was collected at Baystate Medical Center, Springfield, Mass during 1986 on Risk Factors Associated with Low Infant Birth Weight.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe same dataset can be loaded directly from the MASS package. However, for additional learnings, we have provided the dataset in varied formats for the participants to learn data import during the group activities.\n\n\n\n\n\nWe would like to reiterate that creating a project and required folders at the beginning of a research work is a gold standard database management strategy. Go ahead and create your own projects and folders for the activity.\n\n\n\nTo use functions from varied packages/ libraries other than baseR, we need to explicitly load those libraries. For this session, following libraries will be used:-\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe loading of libraries into your current session can be optional. In case you are going to use a function only once from a library, it is computationally better to explicity call the function using ::. Discuss!\n\n\n\nrio: A Swiss-Army Knife for Data I/O (Click to learn more)\ntidyverse: R packages for Data Science (Click to learn more)\nskimr: For quick summary statistics (Click to learn more)\nhere: A Simpler Way to Find Your Files (Click to learn more)\nMASS: Functions and datasets to support Venables and Ripley, “Modern Applied Statistics with S” (4th edition, 2002) (Click to learn more)\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(gtsummary)\n\n\n\n\n\n\n\nCode\ndf &lt;- MASS::birthwt\n\n\n\n\n\nR possesses a simple generic function mechanism which can be used for an object-oriented style of programming (OOP). Method dispatch takes place based on the class of the first argument to the generic function.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen dealing with rectagular spreadsheets, it is a good habit to set the class of the dataset to tibble for a tidy analysis.\n\n\n\n\nCode\nclass(df)\n\n\n[1] \"data.frame\"\n\n\n\n\n\n\n\nCode\ndf &lt;- df |&gt; as_tibble()\nclass(df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\nimport function from the rio package read a data.frame from a file. Exceptions to this rule are Rdata, RDS, and JSON input file formats, which return the originally saved object without changing its class. To set a class, we can use an argument setclass.\n\n\nCode\ndf &lt;- rio::import(here::here(\"data\",\n                             \"lbw.dta\"),\n                  setclass = \"tibble\")\nclass(df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n\n\nglimpse() is like a transposed version of print(): columns run down the page, and data runs across. This makes it possible to see every column in a data frame. It’s a little like str() applied to a data frame but it tries to show you as much data as possible.\n\n\nCode\nglimpse(df)\n\n\nRows: 189\nColumns: 10\n$ low   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age   &lt;dbl&gt; 19, 33, 20, 21, 18, 21, 22, 17, 29, 26, 19, 19, 22, 30, 18, 18, …\n$ lwt   &lt;dbl&gt; 182, 155, 105, 108, 107, 124, 118, 103, 123, 113, 95, 150, 95, 1…\n$ race  &lt;dbl&gt; 2, 3, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1…\n$ smoke &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0…\n$ ptl   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ht    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ui    &lt;dbl&gt; 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1…\n$ ftv   &lt;dbl&gt; 0, 3, 1, 2, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 3, 0, 1, 2, 3…\n$ bwt   &lt;dbl&gt; 2523, 2551, 2557, 2594, 2600, 2622, 2637, 2637, 2663, 2665, 2722…\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnderstanding the data structure helps you understand the way data cleaning/wrangling and subsequent analysis is required. Here, the birthwt data frame has 189 rows and 10 columns. All the variables are dbl (means double precision, a quantitative variable that is essentially continuous - taking decimal values).\n\n\n\n\n\n\n\nsummary() is a generic function used to produce result summaries of the results of various model fitting functions. The function invokes particular methods which depend on the class of the first argument.\n\n\nCode\nsummary(df)\n\n\n      low              age             lwt             race      \n Min.   :0.0000   Min.   :14.00   Min.   : 80.0   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:19.00   1st Qu.:110.0   1st Qu.:1.000  \n Median :0.0000   Median :23.00   Median :121.0   Median :1.000  \n Mean   :0.3122   Mean   :23.24   Mean   :129.8   Mean   :1.847  \n 3rd Qu.:1.0000   3rd Qu.:26.00   3rd Qu.:140.0   3rd Qu.:3.000  \n Max.   :1.0000   Max.   :45.00   Max.   :250.0   Max.   :3.000  \n     smoke             ptl               ht                ui        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000  \n Mean   :0.3915   Mean   :0.1958   Mean   :0.06349   Mean   :0.1481  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :3.0000   Max.   :1.00000   Max.   :1.0000  \n      ftv              bwt      \n Min.   :0.0000   Min.   : 709  \n 1st Qu.:0.0000   1st Qu.:2414  \n Median :0.0000   Median :2977  \n Mean   :0.7937   Mean   :2945  \n 3rd Qu.:1.0000   3rd Qu.:3487  \n Max.   :6.0000   Max.   :4990  \n\n\n\n\n\n\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\n\nCode\nskimr::skim(df)\n\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n189\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n10\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlow\n0\n1\n0.31\n0.46\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nage\n0\n1\n23.24\n5.30\n14\n19\n23\n26\n45\n▇▇▃▁▁\n\n\nlwt\n0\n1\n129.81\n30.58\n80\n110\n121\n140\n250\n▆▇▂▁▁\n\n\nrace\n0\n1\n1.85\n0.92\n1\n1\n1\n3\n3\n▇▁▂▁▆\n\n\nsmoke\n0\n1\n0.39\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▅\n\n\nptl\n0\n1\n0.20\n0.49\n0\n0\n0\n0\n3\n▇▁▁▁▁\n\n\nht\n0\n1\n0.06\n0.24\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nui\n0\n1\n0.15\n0.36\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nftv\n0\n1\n0.79\n1.06\n0\n0\n0\n1\n6\n▇▂▁▁▁\n\n\nbwt\n0\n1\n2944.59\n729.21\n709\n2414\n2977\n3487\n4990\n▁▅▇▆▁\n\n\n\n\n\n\n\n\n\ndplyr is a package grouped inside tidyverse collection of packages. dplyr package is very useful to “munge”, “wrangle”, or “transform” your data. It is a grammar of data manipulation. It provides a consistent set of verbs that help you solve the most common data manipulation challenges.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe common data wrangling functions include:\n\nrename(): To change the names of the variables.\n\nselect(): To reduce the size of dataset by selecting certain variables (or columns).\n\nmutate(): To generate new variable/ transform existing variables.\n\narrange(): To sort observation of a variable.\n\nfilter(): To group observations based on certain criteria.\n\ngroup_by(): To reduce variables to groups in order to estimate summary statistic.\n\n\n\n\n\nrename() provides several advantages over traditional renaming methods, especially in the context of data manipulation.\n\nThe syntax for rename() is concise and intuitive. You specify the new column name first, making it easier to read and understand.\n\nrename() integrates well with the pipe operator (|&gt;), which allows chaining multiple data manipulation steps.\n\nrename() allows you to rename only the columns you need without affecting others. This is convenient when working with large datasets.\n\nIf you try to rename a column that doesn’t exist, rename() throws an informative error, helping catch typos early. This behavior is safer compared to manually changing column names, where typos might go unnoticed.\n\n\n\nCode\ndf &lt;- df |&gt; \n  rename(child_weight_cat = low,\n         maternal_age = age,\n         maternal_weight = lwt,\n         number_preterm = ptl,\n         hypertension = ht,\n         uterine_irritability = ui,\n         health_visits = ftv,\n         birth_weight = bwt)\nnames(df)\n\n\n [1] \"child_weight_cat\"     \"maternal_age\"         \"maternal_weight\"     \n [4] \"race\"                 \"smoke\"                \"number_preterm\"      \n [7] \"hypertension\"         \"uterine_irritability\" \"health_visits\"       \n[10] \"birth_weight\"        \n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(maternal_weight,\n         smoke,\n         birth_weight)\n\n\n# A tibble: 189 × 3\n   maternal_weight smoke birth_weight\n             &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n 1             182     0         2523\n 2             155     0         2551\n 3             105     1         2557\n 4             108     1         2594\n 5             107     1         2600\n 6             124     0         2622\n 7             118     0         2637\n 8             103     0         2637\n 9             123     1         2663\n10             113     1         2665\n# ℹ 179 more rows\n\n\n\n\n\nThe function factor is used to encode a vector as a factor. The same can be used within the mutate function as an argument for data transformation.\n\n\nTry using if else!\n\ndf |&gt; \n  mutate(\n    smoke_cat = if_else(\n      smoke == 1, \"Smoker\", \"Non-Smoker\"))\n\n\n\nCode\ndf &lt;- df |&gt; \n  mutate(smoke_cat = factor(smoke, \n                            levels = c(0,1),\n                            labels = c(\"Non-smoker\",\n                                       \"Smoker\")),\n         race_cat = factor(race,\n                           levels = c(1,2,3),\n                           labels = c(\"White\",\n                                      \"Black\",\n                                      \"Other\")),\n         child_weight_cat = factor(child_weight_cat,\n                                   levels = c(0,1),\n                                   labels = c(\"Normal\", \"Low Birth Weight\")))\ndf |&gt; \n  select(smoke_cat, race_cat, child_weight_cat) |&gt; \n  summary()\n\n\n      smoke_cat    race_cat          child_weight_cat\n Non-smoker:115   White:96   Normal          :130    \n Smoker    : 74   Black:26   Low Birth Weight: 59    \n                  Other:67                           \n\n\n\n\n\n\n\nCode\ndf |&gt; \n  arrange(maternal_age) |&gt; \n  head()\n\n\n# A tibble: 6 × 12\n  child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n  &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1 Normal                     14             135     1     0              0\n2 Low Birth Weight           14             101     3     1              1\n3 Low Birth Weight           14             100     3     0              0\n4 Normal                     15              98     2     0              0\n5 Low Birth Weight           15             110     1     0              0\n6 Low Birth Weight           15             115     3     0              0\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  arrange(-maternal_age) |&gt; \n  head()\n\n\n# A tibble: 6 × 12\n  child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n  &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1 Normal                     45             123     1     0              0\n2 Normal                     36             202     1     0              0\n3 Normal                     36             175     1     0              0\n4 Normal                     35             121     2     1              1\n5 Normal                     35             170     1     0              1\n6 Low Birth Weight           34             187     2     1              0\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  filter(race_cat == \"Black\")\n\n\n# A tibble: 26 × 12\n   child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n   &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n 1 Normal                     19             182     2     0              0\n 2 Normal                     15              98     2     0              0\n 3 Normal                     26             168     2     1              0\n 4 Normal                     17             113     2     0              0\n 5 Normal                     17             113     2     0              0\n 6 Normal                     35             121     2     1              1\n 7 Normal                     25             125     2     0              0\n 8 Normal                     21             185     2     1              0\n 9 Normal                     23             130     2     0              0\n10 Normal                     22             158     2     0              1\n# ℹ 16 more rows\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\nMost data operations are done on groups defined by variables. group_by() takes an existing tbl and converts it into a grouped tbl where operations are performed “by group”.\n\n\nCode\ndf |&gt; \n  group_by(race_cat)\n\n\n# A tibble: 189 × 12\n# Groups:   race_cat [3]\n   child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n   &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n 1 Normal                     19             182     2     0              0\n 2 Normal                     33             155     3     0              0\n 3 Normal                     20             105     1     1              0\n 4 Normal                     21             108     1     1              0\n 5 Normal                     18             107     1     1              0\n 6 Normal                     21             124     3     0              0\n 7 Normal                     22             118     1     0              0\n 8 Normal                     17             103     3     0              0\n 9 Normal                     29             123     1     1              0\n10 Normal                     26             113     1     1              0\n# ℹ 179 more rows\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\n\nIn this session, we worked on understanding the data structure, variable names, class, and used dplyr verbs for data wrangling. Once the dataset is ready for analysis, we move towards Exploratory Data Analysis. It is an iterative process for a robust analysis later."
  },
  {
    "objectID": "understand_wrangle.html#introduction-to-the-dataset.",
    "href": "understand_wrangle.html#introduction-to-the-dataset.",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "We will be introducing birthwt dataset from the MASS package which was collected at Baystate Medical Center, Springfield, Mass during 1986 on Risk Factors Associated with Low Infant Birth Weight.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe same dataset can be loaded directly from the MASS package. However, for additional learnings, we have provided the dataset in varied formats for the participants to learn data import during the group activities."
  },
  {
    "objectID": "understand_wrangle.html#create-project",
    "href": "understand_wrangle.html#create-project",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "We would like to reiterate that creating a project and required folders at the beginning of a research work is a gold standard database management strategy. Go ahead and create your own projects and folders for the activity."
  },
  {
    "objectID": "understand_wrangle.html#load-libraries",
    "href": "understand_wrangle.html#load-libraries",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "To use functions from varied packages/ libraries other than baseR, we need to explicitly load those libraries. For this session, following libraries will be used:-\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe loading of libraries into your current session can be optional. In case you are going to use a function only once from a library, it is computationally better to explicity call the function using ::. Discuss!\n\n\n\nrio: A Swiss-Army Knife for Data I/O (Click to learn more)\ntidyverse: R packages for Data Science (Click to learn more)\nskimr: For quick summary statistics (Click to learn more)\nhere: A Simpler Way to Find Your Files (Click to learn more)\nMASS: Functions and datasets to support Venables and Ripley, “Modern Applied Statistics with S” (4th edition, 2002) (Click to learn more)\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(gtsummary)"
  },
  {
    "objectID": "understand_wrangle.html#load-data",
    "href": "understand_wrangle.html#load-data",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "Code\ndf &lt;- MASS::birthwt"
  },
  {
    "objectID": "understand_wrangle.html#know-the-class-of-your-data",
    "href": "understand_wrangle.html#know-the-class-of-your-data",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "R possesses a simple generic function mechanism which can be used for an object-oriented style of programming (OOP). Method dispatch takes place based on the class of the first argument to the generic function.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen dealing with rectagular spreadsheets, it is a good habit to set the class of the dataset to tibble for a tidy analysis.\n\n\n\n\nCode\nclass(df)\n\n\n[1] \"data.frame\""
  },
  {
    "objectID": "understand_wrangle.html#setting-dataset-class-to-tibble",
    "href": "understand_wrangle.html#setting-dataset-class-to-tibble",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "Code\ndf &lt;- df |&gt; as_tibble()\nclass(df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "understand_wrangle.html#loading-data-from-a-folder",
    "href": "understand_wrangle.html#loading-data-from-a-folder",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "import function from the rio package read a data.frame from a file. Exceptions to this rule are Rdata, RDS, and JSON input file formats, which return the originally saved object without changing its class. To set a class, we can use an argument setclass.\n\n\nCode\ndf &lt;- rio::import(here::here(\"data\",\n                             \"lbw.dta\"),\n                  setclass = \"tibble\")\nclass(df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "understand_wrangle.html#understand-structure-of-the-data.",
    "href": "understand_wrangle.html#understand-structure-of-the-data.",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "glimpse() is like a transposed version of print(): columns run down the page, and data runs across. This makes it possible to see every column in a data frame. It’s a little like str() applied to a data frame but it tries to show you as much data as possible.\n\n\nCode\nglimpse(df)\n\n\nRows: 189\nColumns: 10\n$ low   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ age   &lt;dbl&gt; 19, 33, 20, 21, 18, 21, 22, 17, 29, 26, 19, 19, 22, 30, 18, 18, …\n$ lwt   &lt;dbl&gt; 182, 155, 105, 108, 107, 124, 118, 103, 123, 113, 95, 150, 95, 1…\n$ race  &lt;dbl&gt; 2, 3, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1…\n$ smoke &lt;dbl&gt; 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0…\n$ ptl   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ht    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ui    &lt;dbl&gt; 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1…\n$ ftv   &lt;dbl&gt; 0, 3, 1, 2, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 0, 0, 3, 0, 1, 2, 3…\n$ bwt   &lt;dbl&gt; 2523, 2551, 2557, 2594, 2600, 2622, 2637, 2637, 2663, 2665, 2722…\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnderstanding the data structure helps you understand the way data cleaning/wrangling and subsequent analysis is required. Here, the birthwt data frame has 189 rows and 10 columns. All the variables are dbl (means double precision, a quantitative variable that is essentially continuous - taking decimal values).\n\n\n\n\n\n\n\nsummary() is a generic function used to produce result summaries of the results of various model fitting functions. The function invokes particular methods which depend on the class of the first argument.\n\n\nCode\nsummary(df)\n\n\n      low              age             lwt             race      \n Min.   :0.0000   Min.   :14.00   Min.   : 80.0   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:19.00   1st Qu.:110.0   1st Qu.:1.000  \n Median :0.0000   Median :23.00   Median :121.0   Median :1.000  \n Mean   :0.3122   Mean   :23.24   Mean   :129.8   Mean   :1.847  \n 3rd Qu.:1.0000   3rd Qu.:26.00   3rd Qu.:140.0   3rd Qu.:3.000  \n Max.   :1.0000   Max.   :45.00   Max.   :250.0   Max.   :3.000  \n     smoke             ptl               ht                ui        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000  \n Mean   :0.3915   Mean   :0.1958   Mean   :0.06349   Mean   :0.1481  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :3.0000   Max.   :1.00000   Max.   :1.0000  \n      ftv              bwt      \n Min.   :0.0000   Min.   : 709  \n 1st Qu.:0.0000   1st Qu.:2414  \n Median :0.0000   Median :2977  \n Mean   :0.7937   Mean   :2945  \n 3rd Qu.:1.0000   3rd Qu.:3487  \n Max.   :6.0000   Max.   :4990  \n\n\n\n\n\n\n\nskim() is an alternative to summary(), quickly providing a broad overview of a data frame. It handles data of all types, dispatching a different set of summary functions based on the types of columns in the data frame.\n\n\nCode\nskimr::skim(df)\n\n\n\nData summary\n\n\nName\ndf\n\n\nNumber of rows\n189\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n10\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlow\n0\n1\n0.31\n0.46\n0\n0\n0\n1\n1\n▇▁▁▁▃\n\n\nage\n0\n1\n23.24\n5.30\n14\n19\n23\n26\n45\n▇▇▃▁▁\n\n\nlwt\n0\n1\n129.81\n30.58\n80\n110\n121\n140\n250\n▆▇▂▁▁\n\n\nrace\n0\n1\n1.85\n0.92\n1\n1\n1\n3\n3\n▇▁▂▁▆\n\n\nsmoke\n0\n1\n0.39\n0.49\n0\n0\n0\n1\n1\n▇▁▁▁▅\n\n\nptl\n0\n1\n0.20\n0.49\n0\n0\n0\n0\n3\n▇▁▁▁▁\n\n\nht\n0\n1\n0.06\n0.24\n0\n0\n0\n0\n1\n▇▁▁▁▁\n\n\nui\n0\n1\n0.15\n0.36\n0\n0\n0\n0\n1\n▇▁▁▁▂\n\n\nftv\n0\n1\n0.79\n1.06\n0\n0\n0\n1\n6\n▇▂▁▁▁\n\n\nbwt\n0\n1\n2944.59\n729.21\n709\n2414\n2977\n3487\n4990\n▁▅▇▆▁"
  },
  {
    "objectID": "understand_wrangle.html#data-wrangling.",
    "href": "understand_wrangle.html#data-wrangling.",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "dplyr is a package grouped inside tidyverse collection of packages. dplyr package is very useful to “munge”, “wrangle”, or “transform” your data. It is a grammar of data manipulation. It provides a consistent set of verbs that help you solve the most common data manipulation challenges.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe common data wrangling functions include:\n\nrename(): To change the names of the variables.\n\nselect(): To reduce the size of dataset by selecting certain variables (or columns).\n\nmutate(): To generate new variable/ transform existing variables.\n\narrange(): To sort observation of a variable.\n\nfilter(): To group observations based on certain criteria.\n\ngroup_by(): To reduce variables to groups in order to estimate summary statistic.\n\n\n\n\n\nrename() provides several advantages over traditional renaming methods, especially in the context of data manipulation.\n\nThe syntax for rename() is concise and intuitive. You specify the new column name first, making it easier to read and understand.\n\nrename() integrates well with the pipe operator (|&gt;), which allows chaining multiple data manipulation steps.\n\nrename() allows you to rename only the columns you need without affecting others. This is convenient when working with large datasets.\n\nIf you try to rename a column that doesn’t exist, rename() throws an informative error, helping catch typos early. This behavior is safer compared to manually changing column names, where typos might go unnoticed.\n\n\n\nCode\ndf &lt;- df |&gt; \n  rename(child_weight_cat = low,\n         maternal_age = age,\n         maternal_weight = lwt,\n         number_preterm = ptl,\n         hypertension = ht,\n         uterine_irritability = ui,\n         health_visits = ftv,\n         birth_weight = bwt)\nnames(df)\n\n\n [1] \"child_weight_cat\"     \"maternal_age\"         \"maternal_weight\"     \n [4] \"race\"                 \"smoke\"                \"number_preterm\"      \n [7] \"hypertension\"         \"uterine_irritability\" \"health_visits\"       \n[10] \"birth_weight\"        \n\n\n\n\n\n\n\nCode\ndf |&gt; \n  select(maternal_weight,\n         smoke,\n         birth_weight)\n\n\n# A tibble: 189 × 3\n   maternal_weight smoke birth_weight\n             &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n 1             182     0         2523\n 2             155     0         2551\n 3             105     1         2557\n 4             108     1         2594\n 5             107     1         2600\n 6             124     0         2622\n 7             118     0         2637\n 8             103     0         2637\n 9             123     1         2663\n10             113     1         2665\n# ℹ 179 more rows\n\n\n\n\n\nThe function factor is used to encode a vector as a factor. The same can be used within the mutate function as an argument for data transformation.\n\n\nTry using if else!\n\ndf |&gt; \n  mutate(\n    smoke_cat = if_else(\n      smoke == 1, \"Smoker\", \"Non-Smoker\"))\n\n\n\nCode\ndf &lt;- df |&gt; \n  mutate(smoke_cat = factor(smoke, \n                            levels = c(0,1),\n                            labels = c(\"Non-smoker\",\n                                       \"Smoker\")),\n         race_cat = factor(race,\n                           levels = c(1,2,3),\n                           labels = c(\"White\",\n                                      \"Black\",\n                                      \"Other\")),\n         child_weight_cat = factor(child_weight_cat,\n                                   levels = c(0,1),\n                                   labels = c(\"Normal\", \"Low Birth Weight\")))\ndf |&gt; \n  select(smoke_cat, race_cat, child_weight_cat) |&gt; \n  summary()\n\n\n      smoke_cat    race_cat          child_weight_cat\n Non-smoker:115   White:96   Normal          :130    \n Smoker    : 74   Black:26   Low Birth Weight: 59    \n                  Other:67                           \n\n\n\n\n\n\n\nCode\ndf |&gt; \n  arrange(maternal_age) |&gt; \n  head()\n\n\n# A tibble: 6 × 12\n  child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n  &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1 Normal                     14             135     1     0              0\n2 Low Birth Weight           14             101     3     1              1\n3 Low Birth Weight           14             100     3     0              0\n4 Normal                     15              98     2     0              0\n5 Low Birth Weight           15             110     1     0              0\n6 Low Birth Weight           15             115     3     0              0\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  arrange(-maternal_age) |&gt; \n  head()\n\n\n# A tibble: 6 × 12\n  child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n  &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n1 Normal                     45             123     1     0              0\n2 Normal                     36             202     1     0              0\n3 Normal                     36             175     1     0              0\n4 Normal                     35             121     2     1              1\n5 Normal                     35             170     1     0              1\n6 Low Birth Weight           34             187     2     1              0\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\n\n\nCode\ndf |&gt; \n  filter(race_cat == \"Black\")\n\n\n# A tibble: 26 × 12\n   child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n   &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n 1 Normal                     19             182     2     0              0\n 2 Normal                     15              98     2     0              0\n 3 Normal                     26             168     2     1              0\n 4 Normal                     17             113     2     0              0\n 5 Normal                     17             113     2     0              0\n 6 Normal                     35             121     2     1              1\n 7 Normal                     25             125     2     0              0\n 8 Normal                     21             185     2     1              0\n 9 Normal                     23             130     2     0              0\n10 Normal                     22             158     2     0              1\n# ℹ 16 more rows\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;\n\n\n\n\n\nMost data operations are done on groups defined by variables. group_by() takes an existing tbl and converts it into a grouped tbl where operations are performed “by group”.\n\n\nCode\ndf |&gt; \n  group_by(race_cat)\n\n\n# A tibble: 189 × 12\n# Groups:   race_cat [3]\n   child_weight_cat maternal_age maternal_weight  race smoke number_preterm\n   &lt;fct&gt;                   &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;\n 1 Normal                     19             182     2     0              0\n 2 Normal                     33             155     3     0              0\n 3 Normal                     20             105     1     1              0\n 4 Normal                     21             108     1     1              0\n 5 Normal                     18             107     1     1              0\n 6 Normal                     21             124     3     0              0\n 7 Normal                     22             118     1     0              0\n 8 Normal                     17             103     3     0              0\n 9 Normal                     29             123     1     1              0\n10 Normal                     26             113     1     1              0\n# ℹ 179 more rows\n# ℹ 6 more variables: hypertension &lt;dbl&gt;, uterine_irritability &lt;dbl&gt;,\n#   health_visits &lt;dbl&gt;, birth_weight &lt;dbl&gt;, smoke_cat &lt;fct&gt;, race_cat &lt;fct&gt;"
  },
  {
    "objectID": "understand_wrangle.html#summary.",
    "href": "understand_wrangle.html#summary.",
    "title": "1 Understanding and wrangling data",
    "section": "",
    "text": "In this session, we worked on understanding the data structure, variable names, class, and used dplyr verbs for data wrangling. Once the dataset is ready for analysis, we move towards Exploratory Data Analysis. It is an iterative process for a robust analysis later."
  }
]